{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08442-ee1e-4a6e-8bc0-6e3a8d32f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares the CV perfromance of a set of predetrmined models \n",
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    maes = []\n",
    "    mses = []\n",
    "    r2s = []\n",
    "    accs = []\n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        mae = -np.round(cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv), 4)\n",
    "        maes.append(mae)\n",
    "        mae_avg = round(mae.mean(), 4)\n",
    "        mse = -np.round(cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv), 4)\n",
    "        mses.append(mse)\n",
    "        mse_avg = round(mse.mean(), 4)\n",
    "        r2 = np.round(cross_val_score(model, X, y, scoring='r2', cv=cv), 4)\n",
    "        r2s.append(r2)\n",
    "        r2_avg = round(r2.mean(), 4)\n",
    "        acc = np.round((100 - (100 * (mae * len(X))) / sum(y)), 4)\n",
    "        accs.append(acc)\n",
    "        acc_avg = round(acc.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [mae_avg, mse_avg, r2_avg, acc_avg]\n",
    "    cv_accuracies.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return cv_accuracies, maes, mses, r2s, accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acefb90-7a6d-4e23-95c7-e375be7cc44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bd69c-4af5-4ab7-9910-e0f29624a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the models to be tested\n",
    "mlr_reg = LinearRegression()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "xgb_reg = xgb_regressor = XGBRegressor(random_state=42)\n",
    "\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = [mlr_reg, rf_reg, xgb_reg]\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comp, maes, mses, r2s, accs = cv_comparison(models, X_train_temp, y_train_temp, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af4b7e-f4ca-4441-88d4-0b56d959f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataFrame for all R^2s\n",
    "r2_comp = pd.DataFrame(r2s, index=comp.columns, columns=['1st Fold', '2nd Fold', '3rd Fold', \n",
    "                                                         '4th Fold'])\n",
    "\n",
    "# Add a column for the averages\n",
    "r2_comp['Average'] = np.round(r2_comp.mean(axis=1),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b7cfe-763e-4af3-9981-7973f4cefee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of trees to be used\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n",
    "\n",
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n",
    "\n",
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
    "\n",
    "# Learning rate\n",
    "xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)]\n",
    "\n",
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n",
    "\n",
    "# Learning objective used\n",
    "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']\n",
    "\n",
    "# Create the grid\n",
    "xgb_grid = {'n_estimators': xgb_n_estimators,\n",
    "            'max_depth': xgb_max_depth,\n",
    "            'min_child_weight': xgb_min_child_weight,\n",
    "            'tree_method': xgb_tree_method,\n",
    "            'eta': xgb_eta,\n",
    "            'gamma': xgb_gamma,\n",
    "            'objective': xgb_objective}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f204e1-ae38-435b-a98d-60a402311c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model to be tuned\n",
    "xgb_base = XGBRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n",
    "                                n_iter = 200, cv = 3, verbose = 2, \n",
    "                                random_state = 420, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "# Get the optimal parameters\n",
    "xgb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891e398-dea2-4576-81d2-2f6e36e29131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the final Multiple Linear Regression\n",
    "mlr_final = LinearRegression()\n",
    "\n",
    "# Create the final Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators = 200,\n",
    "                                 min_samples_split = 6,\n",
    "                                 min_impurity_decrease = 0.0,\n",
    "                                 max_features = 'sqrt',\n",
    "                                 max_depth = 25,\n",
    "                                 criterion = 'mae',\n",
    "                                 bootstrap = True,\n",
    "                                 random_state = 42)\n",
    "\n",
    "# Create the fnal Extreme Gradient Booster\n",
    "xgb_final = XGBRegressor(tree_method = 'exact',\n",
    "                         objective = 'reg:squarederror',\n",
    "                         n_estimators = 1600,\n",
    "                         min_child_weight = 6,\n",
    "                         max_depth = 8,\n",
    "                         gamma = 0,\n",
    "                         eta = 0.1,\n",
    "                         random_state = 42)\n",
    "\n",
    "# Train the models using 80% of the original data\n",
    "mlr_final.fit(X_train_temp, y_train_temp)\n",
    "rf_final.fit(X_train_temp, y_train_temp)\n",
    "xgb_final.fit(X_train_temp, y_train_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c90b1-5bcb-4a2c-a0f9-3697fc72da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function that compares all final models\n",
    "def final_comparison(models, test_features, test_labels):\n",
    "    scores = pd.DataFrame()\n",
    "    for model in models:\n",
    "        predictions = model.predict(test_features)\n",
    "        mae = round(mean_absolute_error(test_labels, predictions), 4)\n",
    "        mse = round(mean_squared_error(test_labels, predictions), 4)\n",
    "        r2 = round(r2_score(test_labels, predictions), 4)\n",
    "        errors = abs(predictions - test_labels)\n",
    "        mape = 100 * np.mean(errors / test_labels)\n",
    "        accuracy = round(100 - mape, 4)\n",
    "        scores[str(model)] = [mae, mse, r2, accuracy]\n",
    "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed61b5d-2dd3-4d43-952a-7bf962262aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Call the comparison function with the three final models\n",
    "final_scores = final_comparison([mlr_final, rf_final, xgb_final], X_test, y_test)\n",
    "\n",
    "# Adjust the column headers\n",
    "final_scores.columns  = ['Linear Regression', 'Random Forest', 'Extreme Gradient Boosting']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
