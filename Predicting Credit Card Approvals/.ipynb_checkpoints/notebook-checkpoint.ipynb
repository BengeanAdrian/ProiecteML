{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 1. Credit card applications\n",
    "<p>Commercial banks receive <em>a lot</em> of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this notebook, we will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_558/img/credit_card.jpg\" alt=\"Credit card being held in hand\"></p>\n",
    "<p>We'll use the <a href=\"http://archive.ics.uci.edu/ml/datasets/credit+approval\">Credit Card Approval dataset</a> from the UCI Machine Learning Repository. The structure of this notebook is as follows:</p>\n",
    "<ul>\n",
    "<li>First, we will start off by loading and viewing the dataset.</li>\n",
    "<li>We will see that the dataset has a mixture of both numerical and non-numerical features, that it contains values from different ranges, plus that it contains a number of missing entries.</li>\n",
    "<li>We will have to preprocess the dataset to ensure the machine learning model we choose can make good predictions.</li>\n",
    "<li>After our data is in good shape, we will do some exploratory data analysis to build our intuitions.</li>\n",
    "<li>Finally, we will build a machine learning model that can predict if an individual's application for a credit card will be accepted.</li>\n",
    "</ul>\n",
    "<p>First, loading and viewing the dataset. We find that since this data is confidential, the contributor of the dataset has anonymized the feature names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
      "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
      "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
      "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
      "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
      "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd \n",
    "# Load dataset\n",
    "cc_apps = pd.read_csv(\"datasets/cc_approvals.data\",header=None)\n",
    "\n",
    "# Inspect data\n",
    "print(cc_apps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "10"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 2. Inspecting the applications\n",
    "<p>The output may appear a bit confusing at its first sight, but let's try to figure out the most important features of a credit card application. The features of this dataset have been anonymized to protect the privacy, but <a href=\"http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\">this blog</a> gives us a pretty good overview of the probable features. The probable features in a typical credit card application are <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code> and finally the <code>ApprovalStatus</code>. This gives us a pretty good starting point, and we can map these features with respect to the columns in the output.   </p>\n",
    "<p>As we can see from our first glance at the data, the dataset has a mixture of numerical and non-numerical features. This can be fixed with some preprocessing, but before we do that, let's learn about the dataset a bit more to see if there are other dataset issues that need to be fixed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "cc_apps_description = cc_apps.describe()\n",
    "print(cc_apps_description)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print DataFrame information\n",
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Inspect missing values in the dataset\n",
    "cc_apps.tail(n=17)\n",
    "#rename the columns of dataframe \n",
    "cc_apps=cc_apps.set_axis(['Gender','Age', 'Debt', 'Married', 'BankCustomer', 'EducationLevel',\n",
    "                   'Ethnicity', 'YearsEmployed', 'PriorDefault', 'Employed', 'CreditScore',\n",
    "                   'DriversLicense','Citizen', 'ZipCode','Income','ApprovalStatus'],axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "17"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. Handling the missing values (part i)\n",
    "<p>We've uncovered some issues that will affect the performance of our machine learning model(s) if they go unchanged:</p>\n",
    "<ul>\n",
    "<li>Our dataset contains both numeric and non-numeric data (specifically data that are of <code>float64</code>, <code>int64</code> and <code>object</code> types). Specifically, the features 2, 7, 10 and 14 contain numeric values (of types float64, float64, int64 and int64 respectively) and all the other features contain non-numeric values.</li>\n",
    "<li>The dataset also contains values from several ranges. Some features have a value range of 0 - 28, some have a range of 2 - 67, and some have a range of 1017 - 100000. Apart from these, we can get useful statistical information (like <code>mean</code>, <code>max</code>, and <code>min</code>) about the features that have numerical values. </li>\n",
    "<li>Finally, the dataset has missing values, which we'll take care of in this task. The missing values in the dataset are labeled with '?', which can be seen in the last cell's output.</li>\n",
    "</ul>\n",
    "<p>Now, let's temporarily replace these missing value question marks with NaN.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Gender    Age    Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
      "673      ?  29.50   2.000       y            p              e         h   \n",
      "674      a  37.33   2.500       u            g              i         h   \n",
      "675      a  41.58   1.040       u            g             aa         v   \n",
      "676      a  30.58  10.665       u            g              q         h   \n",
      "677      b  19.42   7.250       u            g              m         v   \n",
      "678      a  17.92  10.210       u            g             ff        ff   \n",
      "679      a  20.08   1.250       u            g              c         v   \n",
      "680      b  19.50   0.290       u            g              k         v   \n",
      "681      b  27.83   1.000       y            p              d         h   \n",
      "682      b  17.08   3.290       u            g              i         v   \n",
      "683      b  36.42   0.750       y            p              d         v   \n",
      "684      b  40.58   3.290       u            g              m         v   \n",
      "685      b  21.08  10.085       y            p              e         h   \n",
      "686      a  22.67   0.750       u            g              c         v   \n",
      "687      a  25.25  13.500       y            p             ff        ff   \n",
      "688      b  17.92   0.205       u            g             aa         v   \n",
      "689      b  35.00   3.375       u            g              c         h   \n",
      "\n",
      "     YearsEmployed PriorDefault Employed  CreditScore DriversLicense Citizen  \\\n",
      "673          2.000            f        f            0              f       g   \n",
      "674          0.210            f        f            0              f       g   \n",
      "675          0.665            f        f            0              f       g   \n",
      "676          0.085            f        t           12              t       g   \n",
      "677          0.040            f        t            1              f       g   \n",
      "678          0.000            f        f            0              f       g   \n",
      "679          0.000            f        f            0              f       g   \n",
      "680          0.290            f        f            0              f       g   \n",
      "681          3.000            f        f            0              f       g   \n",
      "682          0.335            f        f            0              t       g   \n",
      "683          0.585            f        f            0              f       g   \n",
      "684          3.500            f        f            0              t       s   \n",
      "685          1.250            f        f            0              f       g   \n",
      "686          2.000            f        t            2              t       g   \n",
      "687          2.000            f        t            1              t       g   \n",
      "688          0.040            f        f            0              f       g   \n",
      "689          8.290            f        f            0              t       g   \n",
      "\n",
      "    ZipCode  Income ApprovalStatus  \n",
      "673   00256      17              -  \n",
      "674   00260     246              -  \n",
      "675   00240     237              -  \n",
      "676   00129       3              -  \n",
      "677   00100       1              -  \n",
      "678   00000      50              -  \n",
      "679   00000       0              -  \n",
      "680   00280     364              -  \n",
      "681   00176     537              -  \n",
      "682   00140       2              -  \n",
      "683   00240       3              -  \n",
      "684   00400       0              -  \n",
      "685   00260       0              -  \n",
      "686   00200     394              -  \n",
      "687   00200       1              -  \n",
      "688   00280     750              -  \n",
      "689   00000       0              -  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.50</td>\n",
       "      <td>2.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00256</td>\n",
       "      <td>17</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>a</td>\n",
       "      <td>37.33</td>\n",
       "      <td>2.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>0.210</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>246</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>a</td>\n",
       "      <td>41.58</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.665</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>237</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>a</td>\n",
       "      <td>30.58</td>\n",
       "      <td>10.665</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>0.085</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>12</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00129</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>b</td>\n",
       "      <td>19.42</td>\n",
       "      <td>7.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>a</td>\n",
       "      <td>17.92</td>\n",
       "      <td>10.210</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>50</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>a</td>\n",
       "      <td>20.08</td>\n",
       "      <td>1.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>b</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>364</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>3.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00176</td>\n",
       "      <td>537</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>b</td>\n",
       "      <td>17.08</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>v</td>\n",
       "      <td>0.335</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00140</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>b</td>\n",
       "      <td>36.42</td>\n",
       "      <td>0.750</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>0.585</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>b</td>\n",
       "      <td>40.58</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>3.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>00400</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.250</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender    Age    Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
       "673    NaN  29.50   2.000       y            p              e         h   \n",
       "674      a  37.33   2.500       u            g              i         h   \n",
       "675      a  41.58   1.040       u            g             aa         v   \n",
       "676      a  30.58  10.665       u            g              q         h   \n",
       "677      b  19.42   7.250       u            g              m         v   \n",
       "678      a  17.92  10.210       u            g             ff        ff   \n",
       "679      a  20.08   1.250       u            g              c         v   \n",
       "680      b  19.50   0.290       u            g              k         v   \n",
       "681      b  27.83   1.000       y            p              d         h   \n",
       "682      b  17.08   3.290       u            g              i         v   \n",
       "683      b  36.42   0.750       y            p              d         v   \n",
       "684      b  40.58   3.290       u            g              m         v   \n",
       "685      b  21.08  10.085       y            p              e         h   \n",
       "686      a  22.67   0.750       u            g              c         v   \n",
       "687      a  25.25  13.500       y            p             ff        ff   \n",
       "688      b  17.92   0.205       u            g             aa         v   \n",
       "689      b  35.00   3.375       u            g              c         h   \n",
       "\n",
       "     YearsEmployed PriorDefault Employed  CreditScore DriversLicense Citizen  \\\n",
       "673          2.000            f        f            0              f       g   \n",
       "674          0.210            f        f            0              f       g   \n",
       "675          0.665            f        f            0              f       g   \n",
       "676          0.085            f        t           12              t       g   \n",
       "677          0.040            f        t            1              f       g   \n",
       "678          0.000            f        f            0              f       g   \n",
       "679          0.000            f        f            0              f       g   \n",
       "680          0.290            f        f            0              f       g   \n",
       "681          3.000            f        f            0              f       g   \n",
       "682          0.335            f        f            0              t       g   \n",
       "683          0.585            f        f            0              f       g   \n",
       "684          3.500            f        f            0              t       s   \n",
       "685          1.250            f        f            0              f       g   \n",
       "686          2.000            f        t            2              t       g   \n",
       "687          2.000            f        t            1              t       g   \n",
       "688          0.040            f        f            0              f       g   \n",
       "689          8.290            f        f            0              t       g   \n",
       "\n",
       "    ZipCode  Income ApprovalStatus  \n",
       "673   00256      17              -  \n",
       "674   00260     246              -  \n",
       "675   00240     237              -  \n",
       "676   00129       3              -  \n",
       "677   00100       1              -  \n",
       "678   00000      50              -  \n",
       "679   00000       0              -  \n",
       "680   00280     364              -  \n",
       "681   00176     537              -  \n",
       "682   00140       2              -  \n",
       "683   00240       3              -  \n",
       "684   00400       0              -  \n",
       "685   00260       0              -  \n",
       "686   00200     394              -  \n",
       "687   00200       1              -  \n",
       "688   00280     750              -  \n",
       "689   00000       0              -  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Inspect missing values in the dataset\n",
    "print(cc_apps.tail(17))\n",
    "\n",
    "# Replace the '?'s with NaN\n",
    "cc_apps = cc_apps.replace('?', np.nan)\n",
    "\n",
    "# Inspect the missing values again\n",
    "cc_apps.tail(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "24"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. Handling the missing values (part ii)\n",
    "<p>We replaced all the question marks with NaNs. This is going to help us in the next missing value treatment that we are going to perform.</p>\n",
    "<p>An important question that gets raised here is <em>why are we giving so much importance to missing values</em>? Can't they be just ignored? Ignoring missing values can affect the performance of a machine learning model heavily. While ignoring the missing values our machine learning model may miss out on information about the dataset that may be useful for its training. Then, there are many models which cannot handle missing values implicitly such as LDA. </p>\n",
    "<p>So, to avoid this problem, we are going to impute the missing values with a strategy called mean imputation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dc": {
     "key": "24"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender            12\n",
       "Age               12\n",
       "Debt               0\n",
       "Married            6\n",
       "BankCustomer       6\n",
       "EducationLevel     9\n",
       "Ethnicity          9\n",
       "YearsEmployed      0\n",
       "PriorDefault       0\n",
       "Employed           0\n",
       "CreditScore        0\n",
       "DriversLicense     0\n",
       "Citizen            0\n",
       "ZipCode           13\n",
       "Income             0\n",
       "ApprovalStatus     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute the missing values with mean imputation\n",
    "cc_apps.fillna(cc_apps.mean(), inplace=True)\n",
    "\n",
    "# Count the number of NaNs in the dataset to verify\n",
    "cc_apps.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures/ just helful function \n",
    "import os\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"Predicting Credit Card Approvals\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to see where this missing values are situated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure Initial missingno matrix for dataframe before imputation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt \n",
    "#housing=housing.sort_values(by='LotFrontage')\n",
    "msno.matrix(cc_apps)\n",
    "plt.show() \n",
    "save_fig(\"Initial missingno matrix for dataframe before imputation\")#showing all Nan values on each atribute "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "31"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. Handling the missing values (part iii)\n",
    "<p>We have successfully taken care of the missing values present in the numeric columns. There are still some missing values to be imputed for columns 0, 1, 3, 4, 5, 6 and 13. All of these columns contain non-numeric data and this why the mean imputation strategy would not work here. This needs a different treatment. </p>\n",
    "<p>We are going to impute these missing values with the most frequent values as present in the respective columns. This is <a href=\"https://www.datacamp.com/community/tutorials/categorical-data\">good practice</a> when it comes to imputing missing values for categorical data in general.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender            0\n",
      "Age               0\n",
      "Debt              0\n",
      "Married           0\n",
      "BankCustomer      0\n",
      "EducationLevel    0\n",
      "Ethnicity         0\n",
      "YearsEmployed     0\n",
      "PriorDefault      0\n",
      "Employed          0\n",
      "CreditScore       0\n",
      "DriversLicense    0\n",
      "Citizen           0\n",
      "ZipCode           0\n",
      "Income            0\n",
      "ApprovalStatus    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column of cc_apps\n",
    "for col in cc_apps.columns:\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify.\n",
    "print(cc_apps.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the missing values have been filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure Final missingno matrix for dataframe after imputation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "#housing=housing.sort_values(by='LotFrontage')\n",
    "msno.matrix(cc_apps)\n",
    "plt.show() \n",
    "#showing all Nan values on each atribute \n",
    "save_fig(\"Final missingno matrix for dataframe after imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "38"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Preprocessing the data (part i)\n",
    "<p>The missing values are now successfully handled.</p>\n",
    "<p>There is still some minor but essential data preprocessing needed before we proceed towards building our machine learning model. We are going to divide these remaining preprocessing steps into three main tasks:</p>\n",
    "<ol>\n",
    "<li>Convert the non-numeric data into numeric.</li>\n",
    "<li>Split the data into train and test sets. </li>\n",
    "<li>Scale the feature values to a uniform range.</li>\n",
    "</ol>\n",
    "<p>First, we will be converting all the non-numeric values into numeric ones. We do this because not only it results in a faster computation but also many machine learning models (like XGBoost) (and especially the ones developed using scikit-learn) require the data to be in a strictly numeric format. We will do this by using a technique called <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\">label encoding</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in cc_apps.columns.to_numpy():\n",
    "    # Compare if the dtype is object\n",
    "    if cc_apps[col].dtypes=='object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        cc_apps[col]=le.fit_transform(cc_apps[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Testing corelation between target and other features\n",
    "We need to see if the target is corelated with another features in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApprovalStatus    1.000000\n",
       "Married           0.191431\n",
       "BankCustomer      0.187520\n",
       "Citizen           0.100867\n",
       "ZipCode           0.094851\n",
       "Gender            0.028934\n",
       "Ethnicity        -0.000877\n",
       "DriversLicense   -0.031625\n",
       "EducationLevel   -0.130026\n",
       "Age              -0.133304\n",
       "Income           -0.175657\n",
       "Debt             -0.206294\n",
       "YearsEmployed    -0.322475\n",
       "CreditScore      -0.406410\n",
       "Employed         -0.458301\n",
       "PriorDefault     -0.720407\n",
       "Name: ApprovalStatus, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = cc_apps.corr() \n",
    "corr_matrix[\"ApprovalStatus\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "45"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 7. Splitting the dataset into train and test sets\n",
    "<p>We have successfully converted all the non-numeric values to numeric ones.</p>\n",
    "<p>Now, we will split our data into train set and test set to prepare our data for two different phases of machine learning modeling: training and testing. Ideally, no information from the test data should be used to scale the training data or should be used to direct the training process of a machine learning model. Hence, we first split the data and then apply the scaling.</p>\n",
    "<p>Also, features like <code>DriversLicense</code> and <code>ZipCode</code> are not as important as the other features in the dataset for predicting credit card approvals. We should drop them to design our machine learning model with the best set of features. In Data Science literature, this is often referred to as <em>feature selection</em>. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Gender  Age    Debt  Married  BankCustomer  EducationLevel  Ethnicity  \\\n",
      "0         1  156   0.000        2             1              13          8   \n",
      "1         0  328   4.460        2             1              11          4   \n",
      "2         0   89   0.500        2             1              11          4   \n",
      "3         1  125   1.540        2             1              13          8   \n",
      "4         1   43   5.625        2             1              13          8   \n",
      "..      ...  ...     ...      ...           ...             ...        ...   \n",
      "685       1   52  10.085        3             3               5          4   \n",
      "686       0   71   0.750        2             1               2          8   \n",
      "687       0   97  13.500        3             3               6          3   \n",
      "688       1   20   0.205        2             1               0          8   \n",
      "689       1  197   3.375        2             1               2          4   \n",
      "\n",
      "     YearsEmployed  PriorDefault  Employed  CreditScore  Citizen  Income  \\\n",
      "0             1.25             1         1            1        0       0   \n",
      "1             3.04             1         1            6        0     560   \n",
      "2             1.50             1         0            0        0     824   \n",
      "3             3.75             1         1            5        0       3   \n",
      "4             1.71             1         0            0        2       0   \n",
      "..             ...           ...       ...          ...      ...     ...   \n",
      "685           1.25             0         0            0        0       0   \n",
      "686           2.00             0         1            2        0     394   \n",
      "687           2.00             0         1            1        0       1   \n",
      "688           0.04             0         0            0        0     750   \n",
      "689           8.29             0         0            0        0       0   \n",
      "\n",
      "     ApprovalStatus  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "..              ...  \n",
      "685               1  \n",
      "686               1  \n",
      "687               1  \n",
      "688               1  \n",
      "689               1  \n",
      "\n",
      "[690 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
    "cc_apps = cc_apps.drop(['DriversLicense', 'ZipCode'], axis=1)\n",
    "#get NamesforFeatureImportance\n",
    "names=cc_apps.keys()\n",
    "#verifiy dataframe\n",
    "print(cc_apps)\n",
    "#cc_apps = cc_apps.to_numpy()\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "#X,y = cc_apps[:,0:13] , cc_apps[:,13]\n",
    "X=cc_apps.loc[:, [col for col in cc_apps.columns if col != 'ApprovalStatus']]\n",
    "y=cc_apps.ApprovalStatus\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    ,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "52"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 8. Preprocessing the data (part ii)\n",
    "<p>The data is now split into two separate sets - train and test sets respectively. We are only left with one final preprocessing step of scaling before we can fit a machine learning model to the data. </p>\n",
    "<p>Now, let's try to understand what these scaled values mean in the real world. Let's use <code>CreditScore</code> as an example. The credit score of a person is their creditworthiness based on their credit history. The higher this number, the more financially trustworthy a person is considered to be. So, a <code>CreditScore</code> of 1 is the highest since we're rescaling all the values to the range of 0-1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "59"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 9. Fitting a logistic regression model to the train set\n",
    "<p>Essentially, predicting if a credit card application will be approved or not is a <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\">classification</a> task. <a href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names\">According to UCI</a>, our dataset contains more instances that correspond to \"Denied\" status than instances corresponding to \"Approved\" status. Specifically, out of 690 instances, there are 383 (55.5%) applications that got denied and 307 (44.5%) applications that got approved. </p>\n",
    "<p>This gives us a benchmark. A good machine learning model should be able to accurately predict the status of the applications with respect to these statistics.</p>\n",
    "<p>Which model should we pick? A question to ask is: <em>are the features that affect the credit card approval decision process correlated with each other?</em> Although we can measure correlation, that is outside the scope of this notebook, so we'll rely on our intuition that they indeed are correlated for now. Because of this correlation, we'll take advantage of the fact that generalized linear models perform well in these cases. Let's start our machine learning modeling with a Logistic Regression model (a generalized linear model).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "66"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 10. Making predictions and evaluating performance\n",
    "<p>But how well does our model perform? </p>\n",
    "<p>We will now evaluate our model on the test set with respect to <a href=\"https://developers.google.com/machine-learning/crash-course/classification/accuracy\">classification accuracy</a>. But we will also take a look the model's <a href=\"http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\">confusion matrix</a>. In the case of predicting credit card applications, it is equally important to see if our machine learning model is able to predict the approval status of the applications as denied that originally got denied. If our model is not performing well in this aspect, then it might end up approving the application that should have been approved. The confusion matrix helps us to view our model's performance from these aspects.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dc": {
     "key": "66"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  0.8333333333333334\n",
      "[[60 10]\n",
      " [13 55]]\n"
     ]
    }
   ],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "73"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 11. Grid searching and making the model perform better\n",
    "<p>Our model was pretty good! It was able to yield an accuracy score of almost 84%.</p>\n",
    "<p>For the confusion matrix, the first element of the of the first row of the confusion matrix denotes the true negatives meaning the number of negative instances (denied applications) predicted by the model correctly. And the last element of the second row of the confusion matrix denotes the true positives meaning the number of positive instances (approved applications) predicted by the model correctly.</p>\n",
    "<p>Let's see if we can do better. We can perform a <a href=\"https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\">grid search</a> of the model parameters to improve the model's ability to predict credit card approvals.</p>\n",
    "<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">scikit-learn's implementation of logistic regression</a> consists of different hyperparameters but we will grid search over the following two:</p>\n",
    "<ul>\n",
    "<li>tol</li>\n",
    "<li>max_iter</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dc": {
     "key": "73"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01,0.001,0.0001]\n",
    "max_iter = [100,150,200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
    "param_grid = dict({'tol':tol, 'max_iter':max_iter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "80"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 12. Finding the best performing model\n",
    "<p>We have defined the grid of hyperparameter values and converted them into a single dictionary format which <code>GridSearchCV()</code> expects as one of its parameters. Now, we will begin the grid search to see which values perform best.</p>\n",
    "<p>We will instantiate <code>GridSearchCV()</code> with our earlier <code>logreg</code> model with all the data we have. Instead of passing train and test sets separately, we will supply <code>X</code> (scaled version) and <code>y</code>. We will also instruct <code>GridSearchCV()</code> to perform a <a href=\"https://www.dataschool.io/machine-learning-with-scikit-learn/\">cross-validation</a> of five folds.</p>\n",
    "<p>We'll end the notebook by storing the best-achieved score and the respective best parameters.</p>\n",
    "<p>While building this credit card predictor, we tackled some of the most widely-known preprocessing steps such as <strong>scaling</strong>, <strong>label encoding</strong>, and <strong>missing value imputation</strong>. We finished with some <strong>machine learning</strong> to predict if a person's application for a credit card would get approved or not given some information about that person.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dc": {
     "key": "80"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8507246376811594 {'max_iter': 100, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Use scaler to rescale X and assign it to rescaledX\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# Fit data to grid_model\n",
    "grid_model_result = grid_model.fit(rescaledX, y)\n",
    "\n",
    "# Summarize results\n",
    "best_score= grid_model_result.best_score_\n",
    "best_params = grid_model_result.best_params_\n",
    "print(\"Best Score:\", best_score, best_params) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying LGBM, fit on training set and predict on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.8264705882352942\n"
     ]
    }
   ],
   "source": [
    "# Import XGBClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "# Instantiate gb\n",
    "lgbm = lgb.LGBMClassifier(random_state=42) \n",
    "\n",
    "lgbm.fit(X_train, y_train, eval_metric='auc')\n",
    "\n",
    "# Use XGBoostClassifier to predict instances from the test set and store it\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "#y_pred = xgb.predict_proba(X_test)[:,1]\n",
    "print ('Model score:', roc_auc_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model in process...\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.9146008403361345  We will try better\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.91890756302521  We will try better\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.9123949579831933  We will try better\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.9226890756302522  We will try better\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.9178571428571428  We will try better\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.9142857142857144  We will try better\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "0.9241596638655462  We will try better\n",
      "Best model score: 0.9241596638655462\n",
      "LGBMClassifier(colsample_bytree=0.5, learning_rate=0.01, max_depth=8,\n",
      "               min_child_weight=8, n_estimators=700, random_state=42,\n",
      "               subsample=0.6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "\n",
    "subsample = [0.2,0.4,0.6,0.9]\n",
    "n_estimators = [100,400,700,1000]\n",
    "max_depth = [2,4,6,8]\n",
    "learning_rate = [0.01,0.05,0.1,0.2]\n",
    "colsample_bytree = [0.5,0.6,0.7,0.8]\n",
    "min_child_weight=[2,4,6,8] \n",
    "# Define the grid of hyperparameters to search\n",
    "grid_random = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'subsample': subsample,\n",
    "    'colsample_bytree': colsample_bytree,\n",
    "    'learning_rate': learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "              }\n",
    "\n",
    "print ('Best model in process...')\n",
    "\n",
    "good=True\n",
    "\n",
    "# Set up the random search with 10-fold cross validation\n",
    "random_xgb_cv = RandomizedSearchCV (estimator=lgbm ,\n",
    "            param_distributions= grid_random,\n",
    "            cv=10,\n",
    "            scoring='roc_auc',\n",
    "            verbose=1,\n",
    "            n_jobs=-1,\n",
    "                   )\n",
    "\n",
    "random_xgb_cv.fit(X_train, y_train,eval_metric='auc') \n",
    "\n",
    "# Extract the best estimator\n",
    "best_model_GBR= random_xgb_cv.best_estimator_\n",
    "y_predbest_GBR = best_model_GBR.predict_proba(X_test)[:,1]\n",
    "best_score=roc_auc_score(y_test,y_predbest_GBR)\n",
    "\n",
    "if best_score > 0.923:\n",
    "  print ('Best model score:', best_score)\n",
    "  good=False\n",
    "else : \n",
    "  print(best_score,' We will try better')\n",
    "\n",
    "while good==True and best_score < 0.923: \n",
    "    random_lgb_cv = RandomizedSearchCV (estimator=lgbm ,\n",
    "              param_distributions= grid_random,\n",
    "              cv=10,\n",
    "              scoring='roc_auc',\n",
    "              verbose=1,\n",
    "              n_jobs=-1,\n",
    "                   )\n",
    "\n",
    "    random_xgb_cv.fit(X_train, y_train,eval_metric='auc') \n",
    "\n",
    "    # Extract the best estimator\n",
    "    best_model_GBR= random_xgb_cv.best_estimator_\n",
    "    y_predbest_GBR = best_model_GBR.predict_proba(X_test)[:,1]\n",
    "    best_score=roc_auc_score(y_test,y_predbest_GBR)\n",
    "    print(best_score,' We will try better')\n",
    "    if best_score > 0.923:\n",
    "      print ('Best model score:', roc_auc_score(y_test,y_predbest_GBR ))\n",
    "      print(best_model_GBR)\n",
    "      break\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7176\n",
      "552\n",
      "1794\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "print(X_train.size)\n",
    "print(y_train.size)\n",
    "print(X_test.size)\n",
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-17 18:02:49,379]\u001b[0m A new study created in memory with name: no-name-5ec1247c-df84-4cb1-8cfd-8b05218c40cd\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:49,631]\u001b[0m Trial 0 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 5.248188772766292, 'lambda_l2': 4.417575470998656, 'num_leaves': 165, 'feature_fraction': 0.8572213416136768, 'bagging_fraction': 0.5804518520764872, 'bagging_freq': 6, 'min_child_samples': 69, 'n_estimators': 836, 'max_depth': 10, 'learning_rate': 0.38985392008200753}. Best is trial 0 with value: 0.8913043478260869.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:49,860]\u001b[0m Trial 1 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.6684956597588734, 'lambda_l2': 2.596662509590846, 'num_leaves': 159, 'feature_fraction': 0.42440392873074434, 'bagging_fraction': 0.5851132980949256, 'bagging_freq': 0, 'min_child_samples': 41, 'n_estimators': 744, 'max_depth': 9, 'learning_rate': 0.14736629800897433}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:49,930]\u001b[0m Trial 2 finished with value: 0.8768115942028986 and parameters: {'lambda_l1': 7.561023899833934, 'lambda_l2': 7.165858687539752, 'num_leaves': 17, 'feature_fraction': 0.6437658202709757, 'bagging_fraction': 0.49482396969816944, 'bagging_freq': 3, 'min_child_samples': 75, 'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.4095057582701581}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,206]\u001b[0m Trial 3 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 0.22846778566040865, 'lambda_l2': 8.726289100063267, 'num_leaves': 163, 'feature_fraction': 0.44249919078060934, 'bagging_fraction': 0.46783554554661777, 'bagging_freq': 1, 'min_child_samples': 47, 'n_estimators': 574, 'max_depth': 6, 'learning_rate': 0.3034681868738094}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,266]\u001b[0m Trial 4 finished with value: 0.8768115942028986 and parameters: {'lambda_l1': 7.649357604984371, 'lambda_l2': 1.5092378534474686, 'num_leaves': 42, 'feature_fraction': 0.47376017153710775, 'bagging_fraction': 0.8898452351519299, 'bagging_freq': 6, 'min_child_samples': 44, 'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.4219027230701271}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,297]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,317]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,341]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,363]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,396]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,469]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,529]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,586]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,645]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,771]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,828]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,923]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:50,981]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,117]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 144.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,180]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,241]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,298]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,448]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 149.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,909]\u001b[0m Trial 23 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 0.8824066704552418, 'lambda_l2': 8.227163906913553, 'num_leaves': 176, 'feature_fraction': 0.59151902806672, 'bagging_fraction': 0.4876396708210671, 'bagging_freq': 0, 'min_child_samples': 67, 'n_estimators': 642, 'max_depth': 8, 'learning_rate': 0.32391323969556035}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:51,981]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,069]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 69.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,141]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,200]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,261]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,332]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,401]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,916]\u001b[0m Trial 31 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 1.0568522814697778, 'lambda_l2': 8.587470161122868, 'num_leaves': 174, 'feature_fraction': 0.703482591976758, 'bagging_fraction': 0.47141473283732505, 'bagging_freq': 0, 'min_child_samples': 72, 'n_estimators': 671, 'max_depth': 8, 'learning_rate': 0.32445061549022125}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:52,978]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:53,036]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:53,417]\u001b[0m Trial 34 finished with value: 0.8768115942028986 and parameters: {'lambda_l1': 1.9314431821524898, 'lambda_l2': 9.101006404930581, 'num_leaves': 194, 'feature_fraction': 0.8752866581978932, 'bagging_fraction': 0.45546039860403204, 'bagging_freq': 0, 'min_child_samples': 50, 'n_estimators': 529, 'max_depth': 9, 'learning_rate': 0.4434005855106946}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:53,481]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:53,540]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:54,043]\u001b[0m Trial 37 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 1.049432465606058, 'lambda_l2': 9.91261210726734, 'num_leaves': 204, 'feature_fraction': 0.7679021965499689, 'bagging_fraction': 0.44086647271359114, 'bagging_freq': 0, 'min_child_samples': 56, 'n_estimators': 738, 'max_depth': 6, 'learning_rate': 0.35605059798611816}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:54,568]\u001b[0m Trial 38 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 0.8054401023221277, 'lambda_l2': 8.381602928408405, 'num_leaves': 175, 'feature_fraction': 0.5950150628739558, 'bagging_fraction': 0.4919119082396586, 'bagging_freq': 0, 'min_child_samples': 67, 'n_estimators': 479, 'max_depth': 8, 'learning_rate': 0.3218077088259798}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:54,628]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:54,688]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,140]\u001b[0m Trial 41 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 1.9013029040400329, 'lambda_l2': 8.56858892752752, 'num_leaves': 173, 'feature_fraction': 0.47773610202820704, 'bagging_fraction': 0.4840662000661084, 'bagging_freq': 0, 'min_child_samples': 73, 'n_estimators': 658, 'max_depth': 7, 'learning_rate': 0.31047979530096925}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,203]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,277]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,349]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,412]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,473]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:55,959]\u001b[0m Trial 47 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 2.2766166531074092, 'lambda_l2': 9.238607082341131, 'num_leaves': 212, 'feature_fraction': 0.9223188508970734, 'bagging_fraction': 0.4190191434337962, 'bagging_freq': 0, 'min_child_samples': 78, 'n_estimators': 796, 'max_depth': 6, 'learning_rate': 0.4148549514462878}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,021]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,080]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,141]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,218]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,319]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,377]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,439]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,502]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,567]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,636]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,703]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:56,766]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,343]\u001b[0m Trial 60 finished with value: 0.8768115942028986 and parameters: {'lambda_l1': 1.0887907486617576, 'lambda_l2': 9.529525605481567, 'num_leaves': 219, 'feature_fraction': 0.842142292196655, 'bagging_fraction': 0.5511604953648286, 'bagging_freq': 0, 'min_child_samples': 88, 'n_estimators': 790, 'max_depth': 9, 'learning_rate': 0.37084400501854764}. Best is trial 1 with value: 0.8985507246376812.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,412]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,475]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,534]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,597]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,662]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:57,731]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,270]\u001b[0m Trial 67 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.222642543975714, 'lambda_l2': 9.51716672665794, 'num_leaves': 212, 'feature_fraction': 0.5192456362986857, 'bagging_fraction': 0.5803842890896967, 'bagging_freq': 0, 'min_child_samples': 65, 'n_estimators': 669, 'max_depth': 7, 'learning_rate': 0.3998702933128024}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,332]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,393]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,454]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,518]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,583]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:58,650]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:59,138]\u001b[0m Trial 74 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 1.7496935863807828, 'lambda_l2': 7.162210941655427, 'num_leaves': 191, 'feature_fraction': 0.5688219119320554, 'bagging_fraction': 0.508919162261959, 'bagging_freq': 0, 'min_child_samples': 66, 'n_estimators': 643, 'max_depth': 8, 'learning_rate': 0.343473728890272}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:59,715]\u001b[0m Trial 75 finished with value: 0.8768115942028986 and parameters: {'lambda_l1': 1.62093641435582, 'lambda_l2': 7.987624084641333, 'num_leaves': 181, 'feature_fraction': 0.5840602075355261, 'bagging_fraction': 0.47025299899966616, 'bagging_freq': 0, 'min_child_samples': 71, 'n_estimators': 841, 'max_depth': 8, 'learning_rate': 0.4456427862287087}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:59,795]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:59,877]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:02:59,939]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,001]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,065]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,675]\u001b[0m Trial 81 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 0.8394165463689581, 'lambda_l2': 9.172043661071438, 'num_leaves': 155, 'feature_fraction': 0.8504908684560342, 'bagging_fraction': 0.48995453619863205, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 712, 'max_depth': 6, 'learning_rate': 0.355021923179271}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,738]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,798]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,861]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:00,958]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,031]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,096]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,159]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,229]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,295]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,371]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,432]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,494]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,919]\u001b[0m Trial 94 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.5808972668992203, 'lambda_l2': 8.880870946382874, 'num_leaves': 191, 'feature_fraction': 0.6074504361300077, 'bagging_fraction': 0.44146652559876187, 'bagging_freq': 0, 'min_child_samples': 65, 'n_estimators': 470, 'max_depth': 8, 'learning_rate': 0.4342585606389763}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:01,983]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:02,048]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:02,118]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:02,193]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:02,452]\u001b[0m Trial 99 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 1.782134748156407, 'lambda_l2': 5.434126332720901, 'num_leaves': 185, 'feature_fraction': 0.5010607343542013, 'bagging_fraction': 0.5418940069459803, 'bagging_freq': 0, 'min_child_samples': 75, 'n_estimators': 266, 'max_depth': 8, 'learning_rate': 0.4500395344145942}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:02,517]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:02,786]\u001b[0m Trial 101 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.644387422373428, 'lambda_l2': 5.211953537557605, 'num_leaves': 211, 'feature_fraction': 0.4896676767052535, 'bagging_fraction': 0.5461552177655429, 'bagging_freq': 0, 'min_child_samples': 64, 'n_estimators': 227, 'max_depth': 9, 'learning_rate': 0.425721639357535}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,053]\u001b[0m Trial 102 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 5.457396595019099, 'lambda_l2': 5.070290581717602, 'num_leaves': 219, 'feature_fraction': 0.4935379697470976, 'bagging_fraction': 0.5424440866525944, 'bagging_freq': 0, 'min_child_samples': 63, 'n_estimators': 223, 'max_depth': 9, 'learning_rate': 0.42937724793408066}. Best is trial 67 with value: 0.9057971014492754.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,144]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,210]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,427]\u001b[0m Trial 105 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.203237491783856, 'lambda_l2': 5.637259558559115, 'num_leaves': 155, 'feature_fraction': 0.45391544811386864, 'bagging_fraction': 0.6104929555632567, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.49757812791201117}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,496]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,789]\u001b[0m Trial 107 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.2865950522856857, 'lambda_l2': 5.586367384360327, 'num_leaves': 189, 'feature_fraction': 0.48020493814229687, 'bagging_fraction': 0.5812400970273667, 'bagging_freq': 0, 'min_child_samples': 39, 'n_estimators': 248, 'max_depth': 10, 'learning_rate': 0.4782230221850683}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:03,994]\u001b[0m Trial 108 finished with value: 0.8768115942028986 and parameters: {'lambda_l1': 3.528972068219161, 'lambda_l2': 5.464418116591806, 'num_leaves': 181, 'feature_fraction': 0.47927297007830116, 'bagging_fraction': 0.5763218663856007, 'bagging_freq': 0, 'min_child_samples': 40, 'n_estimators': 232, 'max_depth': 10, 'learning_rate': 0.44219621877938087}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,062]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,139]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,353]\u001b[0m Trial 111 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 2.456579381777149, 'lambda_l2': 4.359111360611379, 'num_leaves': 213, 'feature_fraction': 0.48627504773405517, 'bagging_fraction': 0.6040044629604968, 'bagging_freq': 0, 'min_child_samples': 38, 'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.49920182805249647}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,424]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,626]\u001b[0m Trial 113 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.1231255668134503, 'lambda_l2': 4.001911613797047, 'num_leaves': 17, 'feature_fraction': 0.4723201266618835, 'bagging_fraction': 0.6068558779445329, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 171, 'max_depth': 10, 'learning_rate': 0.4581630022908588}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,820]\u001b[0m Trial 114 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.124056056241013, 'lambda_l2': 3.9930929102837243, 'num_leaves': 32, 'feature_fraction': 0.4666322673297106, 'bagging_fraction': 0.599807675716334, 'bagging_freq': 0, 'min_child_samples': 34, 'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.48683823201022147}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:04,890]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,109]\u001b[0m Trial 116 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.1316481797849716, 'lambda_l2': 3.251561934071465, 'num_leaves': 24, 'feature_fraction': 0.42807756767644956, 'bagging_fraction': 0.5856340890929386, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 204, 'max_depth': 10, 'learning_rate': 0.46323339882663145}. Best is trial 105 with value: 0.9130434782608695.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,180]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,332]\u001b[0m Trial 118 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.7785603485999695, 'lambda_l2': 2.256015115079869, 'num_leaves': 32, 'feature_fraction': 0.4255119050534043, 'bagging_fraction': 0.5681103326369603, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 142, 'max_depth': 10, 'learning_rate': 0.4671878869360155}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,489]\u001b[0m Trial 119 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 3.3122688574407464, 'lambda_l2': 2.3439435175295404, 'num_leaves': 22, 'feature_fraction': 0.43002460093512707, 'bagging_fraction': 0.5659398836571019, 'bagging_freq': 0, 'min_child_samples': 42, 'n_estimators': 136, 'max_depth': 10, 'learning_rate': 0.46682540036712916}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,561]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,735]\u001b[0m Trial 121 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.117831959262528, 'lambda_l2': 1.7906167270772206, 'num_leaves': 31, 'feature_fraction': 0.4674498825432342, 'bagging_fraction': 0.5338948394959222, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 166, 'max_depth': 10, 'learning_rate': 0.4715506636737873}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:05,922]\u001b[0m Trial 122 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.8978995871121078, 'lambda_l2': 1.7094694222445372, 'num_leaves': 29, 'feature_fraction': 0.4429309372711804, 'bagging_fraction': 0.5537051381165325, 'bagging_freq': 0, 'min_child_samples': 50, 'n_estimators': 152, 'max_depth': 10, 'learning_rate': 0.45825707459208953}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,123]\u001b[0m Trial 123 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.1682002933224642, 'lambda_l2': 1.7955276162774851, 'num_leaves': 30, 'feature_fraction': 0.4666412262116455, 'bagging_fraction': 0.550068978639334, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 155, 'max_depth': 10, 'learning_rate': 0.47487798045426005}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,292]\u001b[0m Trial 124 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.128735246148554, 'lambda_l2': 1.7466439428057448, 'num_leaves': 44, 'feature_fraction': 0.4645081589497649, 'bagging_fraction': 0.5593178504548724, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 155, 'max_depth': 10, 'learning_rate': 0.4717046469692084}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,483]\u001b[0m Trial 125 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 1.4729619397787206, 'lambda_l2': 1.7160777486726384, 'num_leaves': 47, 'feature_fraction': 0.4408521671227798, 'bagging_fraction': 0.5584178769664677, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 160, 'max_depth': 10, 'learning_rate': 0.47242097511686054}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,665]\u001b[0m Trial 126 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.4960385539772352, 'lambda_l2': 1.620860358381152, 'num_leaves': 47, 'feature_fraction': 0.46528170474978336, 'bagging_fraction': 0.5609730012519499, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.47387801562740495}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,826]\u001b[0m Trial 127 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.5172581963822895, 'lambda_l2': 1.849897381540938, 'num_leaves': 51, 'feature_fraction': 0.4414834038568922, 'bagging_fraction': 0.5566477917365855, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.46887078617660116}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,894]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:06,959]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,032]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,222]\u001b[0m Trial 131 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.0704231829830606, 'lambda_l2': 1.2757841033985309, 'num_leaves': 28, 'feature_fraction': 0.4638474477254263, 'bagging_fraction': 0.5839719089094231, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.4867806623890821}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,293]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,455]\u001b[0m Trial 133 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.7406521223953868, 'lambda_l2': 1.3984651447909593, 'num_leaves': 48, 'feature_fraction': 0.4565325341773345, 'bagging_fraction': 0.5870176349566972, 'bagging_freq': 0, 'min_child_samples': 39, 'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.4820125799146437}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,530]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,607]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,796]\u001b[0m Trial 136 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.2139077080783904, 'lambda_l2': 2.201536907006279, 'num_leaves': 40, 'feature_fraction': 0.4746031605317973, 'bagging_fraction': 0.6485557868618289, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.4563930785927296}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:07,867]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,102]\u001b[0m Trial 138 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.0012504481446203, 'lambda_l2': 1.7388890361069362, 'num_leaves': 28, 'feature_fraction': 0.45847931312465756, 'bagging_fraction': 0.6274049619170701, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.4722609849930033}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,268]\u001b[0m Trial 139 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.1518547274967603, 'lambda_l2': 2.932468872747237, 'num_leaves': 8, 'feature_fraction': 0.43421547282953266, 'bagging_fraction': 0.6569395345507714, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 142, 'max_depth': 10, 'learning_rate': 0.44695790232725513}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,343]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,502]\u001b[0m Trial 141 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 1.9011515918030348, 'lambda_l2': 1.679998483228158, 'num_leaves': 48, 'feature_fraction': 0.4587390809774395, 'bagging_fraction': 0.5658964518889643, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.47108830862397677}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,586]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,730]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:08,805]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:09,011]\u001b[0m Trial 145 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.9574418373945863, 'lambda_l2': 1.186701514137045, 'num_leaves': 39, 'feature_fraction': 0.4778733603265097, 'bagging_fraction': 0.6479779136193088, 'bagging_freq': 0, 'min_child_samples': 53, 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.43713245107775117}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:09,224]\u001b[0m Trial 146 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.9917332338962455, 'lambda_l2': 1.1800833072136256, 'num_leaves': 36, 'feature_fraction': 0.47460914242777663, 'bagging_fraction': 0.6223026242856252, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 113, 'max_depth': 10, 'learning_rate': 0.43806180871404954}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:09,424]\u001b[0m Trial 147 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.934366953851249, 'lambda_l2': 0.6681707270248475, 'num_leaves': 37, 'feature_fraction': 0.4321845183824934, 'bagging_fraction': 0.6369138011193989, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.43811375564660526}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:09,514]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:09,777]\u001b[0m Trial 149 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 2.5358103478039014, 'lambda_l2': 2.877308644552227, 'num_leaves': 40, 'feature_fraction': 0.42675452875461306, 'bagging_fraction': 0.6468477786997137, 'bagging_freq': 0, 'min_child_samples': 53, 'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.45152666323608504}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:09,871]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:10,078]\u001b[0m Trial 151 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 3.0858328127824954, 'lambda_l2': 1.1079677599141249, 'num_leaves': 56, 'feature_fraction': 0.4553942555039016, 'bagging_fraction': 0.6568928981803261, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.44178939584024707}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:10,295]\u001b[0m Trial 152 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 3.190074666618986, 'lambda_l2': 1.0124707422074508, 'num_leaves': 25, 'feature_fraction': 0.4553841872533177, 'bagging_fraction': 0.5972013311347276, 'bagging_freq': 0, 'min_child_samples': 41, 'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.4833419811638725}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:10,376]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:10,451]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:10,705]\u001b[0m Trial 155 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.66734349205634, 'lambda_l2': 1.4773645674346636, 'num_leaves': 55, 'feature_fraction': 0.4370038879877747, 'bagging_fraction': 0.8211953128912031, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.41990820416612246}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:10,795]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,013]\u001b[0m Trial 157 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.4362561955680393, 'lambda_l2': 1.0399603399932391, 'num_leaves': 43, 'feature_fraction': 0.4645063684995525, 'bagging_fraction': 0.7060373800050437, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 147, 'max_depth': 10, 'learning_rate': 0.4731590898227775}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,231]\u001b[0m Trial 158 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.77723880290995, 'lambda_l2': 1.7329122568124533, 'num_leaves': 58, 'feature_fraction': 0.44551936721684526, 'bagging_fraction': 0.6807784072322954, 'bagging_freq': 0, 'min_child_samples': 50, 'n_estimators': 152, 'max_depth': 10, 'learning_rate': 0.47499566140613836}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,322]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,400]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,580]\u001b[0m Trial 161 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.9633034979365913, 'lambda_l2': 1.1578114304617957, 'num_leaves': 38, 'feature_fraction': 0.48257049332895985, 'bagging_fraction': 0.7016661555840032, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.45667211752764214}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,666]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:11,855]\u001b[0m Trial 163 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.369451674646884, 'lambda_l2': 1.8233345828170737, 'num_leaves': 45, 'feature_fraction': 0.4371630936855861, 'bagging_fraction': 0.537696506233804, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.47269940737255306}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:12,104]\u001b[0m Trial 164 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.0874965143705086, 'lambda_l2': 3.334011665976792, 'num_leaves': 29, 'feature_fraction': 0.46563642821615786, 'bagging_fraction': 0.6022293358586384, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 167, 'max_depth': 10, 'learning_rate': 0.49019024756541874}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:12,306]\u001b[0m Trial 165 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.5243922112400985, 'lambda_l2': 0.9447003036686734, 'num_leaves': 12, 'feature_fraction': 0.42871084658785413, 'bagging_fraction': 0.6368081600870762, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 182, 'max_depth': 10, 'learning_rate': 0.4647176847965696}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:12,377]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:12,543]\u001b[0m Trial 167 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.6886050854554275, 'lambda_l2': 1.5110411441340044, 'num_leaves': 29, 'feature_fraction': 0.43635862139217435, 'bagging_fraction': 0.8467204478382204, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.4218971427728908}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:12,611]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:12,767]\u001b[0m Trial 169 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.5710458242906666, 'lambda_l2': 1.3510484686220612, 'num_leaves': 55, 'feature_fraction': 0.45139322621058714, 'bagging_fraction': 0.8139947824520168, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.43898371845767115}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,028]\u001b[0m Trial 170 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.248094548216824, 'lambda_l2': 2.027513147551977, 'num_leaves': 8, 'feature_fraction': 0.4683039127700122, 'bagging_fraction': 0.6165817308926591, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 160, 'max_depth': 10, 'learning_rate': 0.4821067092802648}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,240]\u001b[0m Trial 171 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.500922737067342, 'lambda_l2': 0.9835239087131857, 'num_leaves': 29, 'feature_fraction': 0.43265171107892925, 'bagging_fraction': 0.8762961332194789, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 122, 'max_depth': 10, 'learning_rate': 0.4227469785346675}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,312]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,488]\u001b[0m Trial 173 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.9566016906708645, 'lambda_l2': 0.8534907383909056, 'num_leaves': 50, 'feature_fraction': 0.4316359011313908, 'bagging_fraction': 0.8679969292745693, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.4062789509696708}. Best is trial 118 with value: 0.9202898550724637.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,564]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,747]\u001b[0m Trial 175 finished with value: 0.927536231884058 and parameters: {'lambda_l1': 1.4072090284667538, 'lambda_l2': 1.8390726765634686, 'num_leaves': 36, 'feature_fraction': 0.4423887488706305, 'bagging_fraction': 0.9482363494904711, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.4763179935478219}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,825]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:13,986]\u001b[0m Trial 177 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.798669169634183, 'lambda_l2': 1.1540929863194078, 'num_leaves': 34, 'feature_fraction': 0.48364734585086305, 'bagging_fraction': 0.6999176615976964, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 112, 'max_depth': 10, 'learning_rate': 0.49544394672638137}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,056]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,248]\u001b[0m Trial 179 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.7735080011297573, 'lambda_l2': 1.351932374993338, 'num_leaves': 37, 'feature_fraction': 0.4282461725712393, 'bagging_fraction': 0.9031108879706226, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.44006514453025786}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,327]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,402]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,555]\u001b[0m Trial 182 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 3.0120444970253875, 'lambda_l2': 1.3592746166539005, 'num_leaves': 38, 'feature_fraction': 0.4545069298626002, 'bagging_fraction': 0.9474793879431477, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.4471344763763018}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,772]\u001b[0m Trial 183 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.6543121777355223, 'lambda_l2': 1.3828342698513623, 'num_leaves': 14, 'feature_fraction': 0.45355782401588063, 'bagging_fraction': 0.9066604378484892, 'bagging_freq': 0, 'min_child_samples': 44, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.44463715803096066}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:14,948]\u001b[0m Trial 184 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 3.211660584285087, 'lambda_l2': 1.3925534219324491, 'num_leaves': 114, 'feature_fraction': 0.4238140478428581, 'bagging_fraction': 0.9476731543677575, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.4286718148566089}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,019]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,188]\u001b[0m Trial 186 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.2009836489601295, 'lambda_l2': 0.6463628568329032, 'num_leaves': 13, 'feature_fraction': 0.4451362399390565, 'bagging_fraction': 0.9240260463003812, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.43078242100027375}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,351]\u001b[0m Trial 187 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 4.178380367937791, 'lambda_l2': 0.5602698901750998, 'num_leaves': 15, 'feature_fraction': 0.44598115586729153, 'bagging_fraction': 0.9061713382375294, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.43134767742326036}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,423]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,566]\u001b[0m Trial 189 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.2348800346394535, 'lambda_l2': 1.3158766982011572, 'num_leaves': 13, 'feature_fraction': 0.45179768622556504, 'bagging_fraction': 0.9244771626651488, 'bagging_freq': 0, 'min_child_samples': 40, 'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.42931165695922063}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,637]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:15,810]\u001b[0m Trial 191 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.0423789760271682, 'lambda_l2': 1.2733852277630389, 'num_leaves': 21, 'feature_fraction': 0.4556852963030598, 'bagging_fraction': 0.9195168044724182, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 118, 'max_depth': 10, 'learning_rate': 0.4465988372506536}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,000]\u001b[0m Trial 192 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 3.2437835298165925, 'lambda_l2': 1.0520131819440255, 'num_leaves': 121, 'feature_fraction': 0.45396123669642047, 'bagging_fraction': 0.949730752540515, 'bagging_freq': 0, 'min_child_samples': 42, 'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.4484527717897264}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,156]\u001b[0m Trial 193 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.6024579636861542, 'lambda_l2': 1.244996744597576, 'num_leaves': 15, 'feature_fraction': 0.4364239122591324, 'bagging_fraction': 0.8932513449858643, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 122, 'max_depth': 10, 'learning_rate': 0.4136521457434043}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,232]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,317]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,467]\u001b[0m Trial 196 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.084520342143333, 'lambda_l2': 0.8233878492754836, 'num_leaves': 19, 'feature_fraction': 0.4433138638550611, 'bagging_fraction': 0.9175787632140546, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.4309176949087885}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,542]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,614]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,761]\u001b[0m Trial 199 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.2593779187536938, 'lambda_l2': 1.2671146466630867, 'num_leaves': 37, 'feature_fraction': 0.44650309814272005, 'bagging_fraction': 0.9270209297706137, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.4470583255168543}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:16,897]\u001b[0m Trial 200 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.9160002753394316, 'lambda_l2': 0.5792339141940959, 'num_leaves': 9, 'feature_fraction': 0.4576436347063141, 'bagging_fraction': 0.9351153859384567, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.42213123723375434}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,050]\u001b[0m Trial 201 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.934549185974688, 'lambda_l2': 0.02876347721076189, 'num_leaves': 14, 'feature_fraction': 0.4593561959998612, 'bagging_fraction': 0.9430899304209072, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.43704790257354453}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,211]\u001b[0m Trial 202 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.8845662178338354, 'lambda_l2': 0.6328652812671767, 'num_leaves': 19, 'feature_fraction': 0.4378198145647437, 'bagging_fraction': 0.9497540462391896, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.44113616461124633}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,281]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,438]\u001b[0m Trial 204 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.986733824006981, 'lambda_l2': 0.462840608430276, 'num_leaves': 19, 'feature_fraction': 0.46200949848830325, 'bagging_fraction': 0.9423946896772348, 'bagging_freq': 0, 'min_child_samples': 44, 'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.4213903786763416}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,515]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,671]\u001b[0m Trial 206 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.429617666178896, 'lambda_l2': 0.40676277061318017, 'num_leaves': 13, 'feature_fraction': 0.4549712069044677, 'bagging_fraction': 0.9179878705394965, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.42026140240703325}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,781]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,924]\u001b[0m Trial 208 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.135693423898013, 'lambda_l2': 0.3935970446191328, 'num_leaves': 14, 'feature_fraction': 0.44596944784050785, 'bagging_fraction': 0.9132549334195297, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.4152639612114153}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:17,994]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,153]\u001b[0m Trial 210 finished with value: 0.927536231884058 and parameters: {'lambda_l1': 2.8561770348531055, 'lambda_l2': 0.6664898893067663, 'num_leaves': 21, 'feature_fraction': 0.4249684731601385, 'bagging_fraction': 0.8917279584484489, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.43630315191599356}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,291]\u001b[0m Trial 211 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.474425660014476, 'lambda_l2': 0.4816018956891892, 'num_leaves': 8, 'feature_fraction': 0.45325593234447603, 'bagging_fraction': 0.9359269381384888, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.41640943165980215}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,483]\u001b[0m Trial 212 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.8252866727755777, 'lambda_l2': 0.7517781461800804, 'num_leaves': 21, 'feature_fraction': 0.4239569858581677, 'bagging_fraction': 0.937247051797752, 'bagging_freq': 0, 'min_child_samples': 38, 'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.4349373571759066}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,626]\u001b[0m Trial 213 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.8718494134926424, 'lambda_l2': 0.7121295812942449, 'num_leaves': 21, 'feature_fraction': 0.42598799222991124, 'bagging_fraction': 0.8914206312667102, 'bagging_freq': 0, 'min_child_samples': 38, 'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.43619205142544204}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,700]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,766]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,835]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,907]\u001b[0m Trial 217 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:18,973]\u001b[0m Trial 218 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,123]\u001b[0m Trial 219 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.67725483763729, 'lambda_l2': 0.5944173663086032, 'num_leaves': 16, 'feature_fraction': 0.4422178183893414, 'bagging_fraction': 0.9378116837589001, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.4326520816907943}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,280]\u001b[0m Trial 220 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.5897596121856727, 'lambda_l2': 0.8459892642982725, 'num_leaves': 88, 'feature_fraction': 0.4305143569029505, 'bagging_fraction': 0.8929270479015202, 'bagging_freq': 0, 'min_child_samples': 53, 'n_estimators': 142, 'max_depth': 10, 'learning_rate': 0.45024925981428526}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,441]\u001b[0m Trial 221 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.8945928639163068, 'lambda_l2': 0.22250509201899404, 'num_leaves': 28, 'feature_fraction': 0.4722109074051259, 'bagging_fraction': 0.9301174814449764, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 130, 'max_depth': 10, 'learning_rate': 0.3995888751732796}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,508]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,576]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,745]\u001b[0m Trial 224 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.6748995201232204, 'lambda_l2': 0.8490689613979071, 'num_leaves': 38, 'feature_fraction': 0.43346741245088427, 'bagging_fraction': 0.8948526150513979, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 133, 'max_depth': 10, 'learning_rate': 0.4418373472627024}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,812]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:19,878]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,024]\u001b[0m Trial 227 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.6802992055090864, 'lambda_l2': 1.5213741348801806, 'num_leaves': 19, 'feature_fraction': 0.4410278795285266, 'bagging_fraction': 0.9280581893238828, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.43451520249319425}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,164]\u001b[0m Trial 228 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.9129222512178523, 'lambda_l2': 1.7916082276707617, 'num_leaves': 22, 'feature_fraction': 0.4389229129202197, 'bagging_fraction': 0.9302192930493405, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 104, 'max_depth': 10, 'learning_rate': 0.4619463081954937}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,236]\u001b[0m Trial 229 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,307]\u001b[0m Trial 230 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,450]\u001b[0m Trial 231 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.2670259863869817, 'lambda_l2': 0.6100867465160481, 'num_leaves': 13, 'feature_fraction': 0.45101483638921064, 'bagging_fraction': 0.9177303724306953, 'bagging_freq': 0, 'min_child_samples': 40, 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.42809960629828736}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,601]\u001b[0m Trial 232 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.187442794254875, 'lambda_l2': 1.0658098314944104, 'num_leaves': 9, 'feature_fraction': 0.44562376416562605, 'bagging_fraction': 0.949741577636022, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.4369598008777899}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,670]\u001b[0m Trial 233 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,740]\u001b[0m Trial 234 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,880]\u001b[0m Trial 235 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.4481606480953504, 'lambda_l2': 0.39250812096602145, 'num_leaves': 13, 'feature_fraction': 0.4492681268517337, 'bagging_fraction': 0.9206588775323452, 'bagging_freq': 0, 'min_child_samples': 42, 'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.41178966336552597}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:20,947]\u001b[0m Trial 236 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,100]\u001b[0m Trial 237 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.6779562888379944, 'lambda_l2': 0.9575540643772347, 'num_leaves': 37, 'feature_fraction': 0.43716563789595975, 'bagging_fraction': 0.9091306315625963, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.41980877034037833}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,171]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,322]\u001b[0m Trial 239 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.5103332730667605, 'lambda_l2': 1.9665904313727864, 'num_leaves': 18, 'feature_fraction': 0.4589210170068392, 'bagging_fraction': 0.657262724453935, 'bagging_freq': 0, 'min_child_samples': 50, 'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.44247813053117496}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,401]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,553]\u001b[0m Trial 241 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.4104722100676543, 'lambda_l2': 0.5796970766359173, 'num_leaves': 13, 'feature_fraction': 0.4557426891279983, 'bagging_fraction': 0.9239632598044228, 'bagging_freq': 0, 'min_child_samples': 42, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.42765603530670065}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,743]\u001b[0m Trial 242 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.732900897345977, 'lambda_l2': 1.2609027767861198, 'num_leaves': 14, 'feature_fraction': 0.4298109200351648, 'bagging_fraction': 0.9384914561973683, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.43587961992708646}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,817]\u001b[0m Trial 243 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:21,951]\u001b[0m Trial 244 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.4809713896652297, 'lambda_l2': 0.43819966551021056, 'num_leaves': 12, 'feature_fraction': 0.44841455460580754, 'bagging_fraction': 0.9350552712776203, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.42459013614970975}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,021]\u001b[0m Trial 245 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,182]\u001b[0m Trial 246 finished with value: 0.927536231884058 and parameters: {'lambda_l1': 2.642122126072374, 'lambda_l2': 0.9048728046018102, 'num_leaves': 46, 'feature_fraction': 0.439552743246341, 'bagging_fraction': 0.9417568127889334, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.4342971061631148}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,338]\u001b[0m Trial 247 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.606215015631592, 'lambda_l2': 0.46757001141356713, 'num_leaves': 47, 'feature_fraction': 0.4368088699785146, 'bagging_fraction': 0.9428385489588795, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.4060446105875929}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,486]\u001b[0m Trial 248 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.902410076002463, 'lambda_l2': 0.8305889303874784, 'num_leaves': 43, 'feature_fraction': 0.4289521822881538, 'bagging_fraction': 0.9380135128153289, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.42211294089088386}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,568]\u001b[0m Trial 249 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,639]\u001b[0m Trial 250 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,712]\u001b[0m Trial 251 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,784]\u001b[0m Trial 252 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:22,926]\u001b[0m Trial 253 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.8364110377636678, 'lambda_l2': 0.8855792691810711, 'num_leaves': 39, 'feature_fraction': 0.4268726943123746, 'bagging_fraction': 0.9385579472011139, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 101, 'max_depth': 10, 'learning_rate': 0.4229080633644974}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,001]\u001b[0m Trial 254 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,075]\u001b[0m Trial 255 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,155]\u001b[0m Trial 256 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,228]\u001b[0m Trial 257 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,380]\u001b[0m Trial 258 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.0451605061069023, 'lambda_l2': 0.3138947958826373, 'num_leaves': 8, 'feature_fraction': 0.44649413830059886, 'bagging_fraction': 0.9494116403022641, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.4009449373295211}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,487]\u001b[0m Trial 259 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,658]\u001b[0m Trial 260 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.6672504776150645, 'lambda_l2': 0.7306963050130332, 'num_leaves': 95, 'feature_fraction': 0.4392388967209001, 'bagging_fraction': 0.8885006746587057, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 121, 'max_depth': 10, 'learning_rate': 0.4117562363617219}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,737]\u001b[0m Trial 261 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,808]\u001b[0m Trial 262 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:23,953]\u001b[0m Trial 263 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.0344976702340873, 'lambda_l2': 1.7641578312145108, 'num_leaves': 15, 'feature_fraction': 0.4574877159414479, 'bagging_fraction': 0.6670164606670389, 'bagging_freq': 0, 'min_child_samples': 40, 'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.44744975047915403}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,026]\u001b[0m Trial 264 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,179]\u001b[0m Trial 265 finished with value: 0.8840579710144928 and parameters: {'lambda_l1': 3.744622656285927, 'lambda_l2': 0.5438282589513714, 'num_leaves': 14, 'feature_fraction': 0.45417670243793373, 'bagging_fraction': 0.9358190493846237, 'bagging_freq': 0, 'min_child_samples': 42, 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.38612914386795383}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,254]\u001b[0m Trial 266 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,418]\u001b[0m Trial 267 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 1.9353828000119515, 'lambda_l2': 1.4829985158093906, 'num_leaves': 29, 'feature_fraction': 0.4740337023384668, 'bagging_fraction': 0.657303631945503, 'bagging_freq': 0, 'min_child_samples': 44, 'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.4651168341350098}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,491]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,562]\u001b[0m Trial 269 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,647]\u001b[0m Trial 270 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,723]\u001b[0m Trial 271 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,795]\u001b[0m Trial 272 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:24,872]\u001b[0m Trial 273 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,028]\u001b[0m Trial 274 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.2413635949859367, 'lambda_l2': 0.24635169489518177, 'num_leaves': 13, 'feature_fraction': 0.440840569205368, 'bagging_fraction': 0.9157468590942724, 'bagging_freq': 0, 'min_child_samples': 44, 'n_estimators': 118, 'max_depth': 10, 'learning_rate': 0.4453943818347651}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,100]\u001b[0m Trial 275 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,247]\u001b[0m Trial 276 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.586940941877024, 'lambda_l2': 0.48939733810401276, 'num_leaves': 36, 'feature_fraction': 0.45111239988398033, 'bagging_fraction': 0.9331817274789793, 'bagging_freq': 0, 'min_child_samples': 42, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.4209090373626143}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,345]\u001b[0m Trial 277 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,417]\u001b[0m Trial 278 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,489]\u001b[0m Trial 279 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,564]\u001b[0m Trial 280 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,639]\u001b[0m Trial 281 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,817]\u001b[0m Trial 282 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.484886328889485, 'lambda_l2': 0.00040895783028454397, 'num_leaves': 37, 'feature_fraction': 0.43502440374018925, 'bagging_fraction': 0.8707251971573371, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 136, 'max_depth': 10, 'learning_rate': 0.4110316888871964}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,891]\u001b[0m Trial 283 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:25,963]\u001b[0m Trial 284 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,117]\u001b[0m Trial 285 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.700706070879852, 'lambda_l2': 1.0816711236544747, 'num_leaves': 22, 'feature_fraction': 0.42922394321430396, 'bagging_fraction': 0.9324613460686108, 'bagging_freq': 0, 'min_child_samples': 43, 'n_estimators': 121, 'max_depth': 10, 'learning_rate': 0.4366168729413608}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,192]\u001b[0m Trial 286 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,265]\u001b[0m Trial 287 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,423]\u001b[0m Trial 288 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 2.6675738796088884, 'lambda_l2': 1.0180089636943075, 'num_leaves': 37, 'feature_fraction': 0.44111675923379845, 'bagging_fraction': 0.9493824577281864, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.43929403121951294}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,513]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,590]\u001b[0m Trial 290 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,674]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,841]\u001b[0m Trial 292 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.8077847065168378, 'lambda_l2': 1.1212811802529155, 'num_leaves': 42, 'feature_fraction': 0.44226154605940476, 'bagging_fraction': 0.7249668989975571, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.4222046215122603}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,919]\u001b[0m Trial 293 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:26,996]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,071]\u001b[0m Trial 295 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,146]\u001b[0m Trial 296 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,222]\u001b[0m Trial 297 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,296]\u001b[0m Trial 298 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,370]\u001b[0m Trial 299 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,468]\u001b[0m Trial 300 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,541]\u001b[0m Trial 301 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,699]\u001b[0m Trial 302 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 3.226325607677646, 'lambda_l2': 1.1103569830097042, 'num_leaves': 37, 'feature_fraction': 0.4447979407250257, 'bagging_fraction': 0.9288505849674881, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.43722817885257376}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:27,866]\u001b[0m Trial 303 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.1517471179315173, 'lambda_l2': 1.2105607185342044, 'num_leaves': 12, 'feature_fraction': 0.4482089742427231, 'bagging_fraction': 0.9253985696387867, 'bagging_freq': 0, 'min_child_samples': 41, 'n_estimators': 113, 'max_depth': 10, 'learning_rate': 0.4400576291730056}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,025]\u001b[0m Trial 304 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.56643690852696, 'lambda_l2': 0.6801323035651516, 'num_leaves': 38, 'feature_fraction': 0.45457992715265605, 'bagging_fraction': 0.6380007145934408, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.44814229835119235}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,305]\u001b[0m Trial 305 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.3530680039456295, 'lambda_l2': 0.45790134276894734, 'num_leaves': 8, 'feature_fraction': 0.46192087634616963, 'bagging_fraction': 0.9371236052373733, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 314, 'max_depth': 10, 'learning_rate': 0.41796198228044934}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,384]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,566]\u001b[0m Trial 307 finished with value: 0.8913043478260869 and parameters: {'lambda_l1': 3.3084977064701553, 'lambda_l2': 5.754969914069346, 'num_leaves': 17, 'feature_fraction': 0.4420831122263088, 'bagging_fraction': 0.9226226905243443, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.43172397224553416}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,643]\u001b[0m Trial 308 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,718]\u001b[0m Trial 309 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,795]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:28,958]\u001b[0m Trial 311 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.7592553011940244, 'lambda_l2': 0.9047973261495865, 'num_leaves': 39, 'feature_fraction': 0.4264677936345277, 'bagging_fraction': 0.8898495569301608, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.4061207621194904}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,112]\u001b[0m Trial 312 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.560673819057762, 'lambda_l2': 0.3998092612386865, 'num_leaves': 17, 'feature_fraction': 0.4496751930678758, 'bagging_fraction': 0.930778621523237, 'bagging_freq': 0, 'min_child_samples': 41, 'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.4190788655217431}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,196]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,290]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,365]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,440]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,516]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,591]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,670]\u001b[0m Trial 319 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,837]\u001b[0m Trial 320 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 2.719884290569974, 'lambda_l2': 0.5724154868748197, 'num_leaves': 89, 'feature_fraction': 0.4394967999444985, 'bagging_fraction': 0.883750164990119, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.4564202722174788}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:29,916]\u001b[0m Trial 321 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,074]\u001b[0m Trial 322 finished with value: 0.9202898550724637 and parameters: {'lambda_l1': 3.1082782278366237, 'lambda_l2': 1.1638790963837895, 'num_leaves': 9, 'feature_fraction': 0.4244508473503001, 'bagging_fraction': 0.9429428758293722, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.43857703938522496}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,250]\u001b[0m Trial 323 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.1126521521992476, 'lambda_l2': 2.168807717492318, 'num_leaves': 29, 'feature_fraction': 0.49456035083583405, 'bagging_fraction': 0.9498145228343837, 'bagging_freq': 0, 'min_child_samples': 48, 'n_estimators': 130, 'max_depth': 10, 'learning_rate': 0.4589660372882733}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,331]\u001b[0m Trial 324 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,409]\u001b[0m Trial 325 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,485]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,561]\u001b[0m Trial 327 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,637]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,791]\u001b[0m Trial 329 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.407416179098802, 'lambda_l2': 0.8625796485643731, 'num_leaves': 15, 'feature_fraction': 0.45678632502736394, 'bagging_fraction': 0.9258838605940672, 'bagging_freq': 7, 'min_child_samples': 43, 'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.44148178553412015}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:30,868]\u001b[0m Trial 330 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,023]\u001b[0m Trial 331 finished with value: 0.9057971014492754 and parameters: {'lambda_l1': 3.096691925995637, 'lambda_l2': 1.475544639675966, 'num_leaves': 17, 'feature_fraction': 0.44446470411495437, 'bagging_fraction': 0.9492250141962931, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.4331186455130454}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,117]\u001b[0m Trial 332 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,195]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,276]\u001b[0m Trial 334 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,447]\u001b[0m Trial 335 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.7340086766883465, 'lambda_l2': 1.4869145893340738, 'num_leaves': 39, 'feature_fraction': 0.4349336008622563, 'bagging_fraction': 0.8728497576464047, 'bagging_freq': 0, 'min_child_samples': 50, 'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.44589638292756345}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,536]\u001b[0m Trial 336 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,617]\u001b[0m Trial 337 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,695]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,877]\u001b[0m Trial 339 finished with value: 0.927536231884058 and parameters: {'lambda_l1': 2.4943713551506503, 'lambda_l2': 0.8871763509206548, 'num_leaves': 42, 'feature_fraction': 0.42885533089087907, 'bagging_fraction': 0.6458678488495863, 'bagging_freq': 0, 'min_child_samples': 49, 'n_estimators': 145, 'max_depth': 9, 'learning_rate': 0.45961885615902665}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:31,969]\u001b[0m Trial 340 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,144]\u001b[0m Trial 341 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.6621695088489687, 'lambda_l2': 0.8701965646827093, 'num_leaves': 41, 'feature_fraction': 0.42694556945364565, 'bagging_fraction': 0.8976912146414495, 'bagging_freq': 0, 'min_child_samples': 51, 'n_estimators': 133, 'max_depth': 10, 'learning_rate': 0.4433536794363946}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,224]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,375]\u001b[0m Trial 343 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 3.09571028397168, 'lambda_l2': 0.9597124263021729, 'num_leaves': 9, 'feature_fraction': 0.4390294848631669, 'bagging_fraction': 0.6321272780885892, 'bagging_freq': 0, 'min_child_samples': 45, 'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.44702353101976383}. Best is trial 175 with value: 0.927536231884058.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,454]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,534]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,613]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,690]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,772]\u001b[0m Trial 348 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,849]\u001b[0m Trial 349 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:32,928]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,010]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,095]\u001b[0m Trial 352 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,180]\u001b[0m Trial 353 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,265]\u001b[0m Trial 354 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,440]\u001b[0m Trial 355 finished with value: 0.9347826086956522 and parameters: {'lambda_l1': 2.6763226060961807, 'lambda_l2': 0.9195667832149104, 'num_leaves': 38, 'feature_fraction': 0.4242409093375889, 'bagging_fraction': 0.8953156358244683, 'bagging_freq': 0, 'min_child_samples': 52, 'n_estimators': 133, 'max_depth': 10, 'learning_rate': 0.44014139535340124}. Best is trial 355 with value: 0.9347826086956522.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,520]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,599]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,682]\u001b[0m Trial 358 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,762]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,840]\u001b[0m Trial 360 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:33,921]\u001b[0m Trial 361 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,001]\u001b[0m Trial 362 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,084]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,165]\u001b[0m Trial 364 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,249]\u001b[0m Trial 365 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,336]\u001b[0m Trial 366 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,458]\u001b[0m Trial 367 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,540]\u001b[0m Trial 368 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,619]\u001b[0m Trial 369 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,701]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,871]\u001b[0m Trial 371 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 3.148959569282457, 'lambda_l2': 1.500812405967225, 'num_leaves': 253, 'feature_fraction': 0.4414778636241596, 'bagging_fraction': 0.9026901998093335, 'bagging_freq': 0, 'min_child_samples': 44, 'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.4577728989866053}. Best is trial 355 with value: 0.9347826086956522.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:34,954]\u001b[0m Trial 372 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,035]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,120]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,206]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,289]\u001b[0m Trial 376 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,455]\u001b[0m Trial 377 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.9139587914727, 'lambda_l2': 1.5583429759814282, 'num_leaves': 18, 'feature_fraction': 0.45061494837856014, 'bagging_fraction': 0.9487273237632431, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.42645493484453095}. Best is trial 355 with value: 0.9347826086956522.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,537]\u001b[0m Trial 378 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,620]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,703]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,887]\u001b[0m Trial 381 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.3696904287963, 'lambda_l2': 1.725264247467216, 'num_leaves': 37, 'feature_fraction': 0.4410085260515918, 'bagging_fraction': 0.6495945474471355, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 135, 'max_depth': 10, 'learning_rate': 0.4306684847658824}. Best is trial 355 with value: 0.9347826086956522.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:35,973]\u001b[0m Trial 382 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,056]\u001b[0m Trial 383 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,142]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,229]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,337]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,431]\u001b[0m Trial 387 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,521]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,609]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,690]\u001b[0m Trial 390 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,777]\u001b[0m Trial 391 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:36,860]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,066]\u001b[0m Trial 393 finished with value: 0.8985507246376812 and parameters: {'lambda_l1': 2.8846505614513642, 'lambda_l2': 1.676981456822331, 'num_leaves': 37, 'feature_fraction': 0.4334230786021242, 'bagging_fraction': 0.6671674492231398, 'bagging_freq': 0, 'min_child_samples': 46, 'n_estimators': 139, 'max_depth': 10, 'learning_rate': 0.4448382382359521}. Best is trial 355 with value: 0.9347826086956522.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,150]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,235]\u001b[0m Trial 395 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,317]\u001b[0m Trial 396 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,489]\u001b[0m Trial 397 finished with value: 0.9130434782608695 and parameters: {'lambda_l1': 2.4209843879205906, 'lambda_l2': 5.326915476416813, 'num_leaves': 43, 'feature_fraction': 0.4848077985521506, 'bagging_fraction': 0.6159513800093103, 'bagging_freq': 0, 'min_child_samples': 47, 'n_estimators': 118, 'max_depth': 10, 'learning_rate': 0.4906505881790144}. Best is trial 355 with value: 0.9347826086956522.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,572]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n",
      "\u001b[32m[I 2022-04-17 18:03:37,655]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.9347826086956522\n",
      "  Params: \n",
      "    lambda_l1: 2.6763226060961807\n",
      "    lambda_l2: 0.9195667832149104\n",
      "    num_leaves: 38\n",
      "    feature_fraction: 0.4242409093375889\n",
      "    bagging_fraction: 0.8953156358244683\n",
      "    bagging_freq: 0\n",
      "    min_child_samples: 52\n",
      "    n_estimators: 133\n",
      "    max_depth: 10\n",
      "    learning_rate: 0.44014139535340124\n",
      "<lightgbm.basic.Booster object at 0x000002A258DFBB80>\n",
      "Best score is: 0.9347826086956522\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          23,
          31,
          34,
          37,
          38,
          41,
          47,
          60,
          67,
          74,
          75,
          81,
          94,
          99,
          101,
          102,
          105,
          107,
          108,
          111,
          113,
          114,
          116,
          118,
          119,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          131,
          133,
          136,
          138,
          139,
          141,
          145,
          146,
          147,
          149,
          151,
          152,
          155,
          157,
          158,
          161,
          163,
          164,
          165,
          167,
          169,
          170,
          171,
          173,
          175,
          177,
          179,
          182,
          183,
          184,
          186,
          187,
          189,
          191,
          192,
          193,
          196,
          199,
          200,
          201,
          202,
          204,
          206,
          208,
          210,
          211,
          212,
          213,
          219,
          220,
          221,
          224,
          227,
          228,
          231,
          232,
          235,
          237,
          239,
          241,
          242,
          244,
          246,
          247,
          248,
          253,
          258,
          260,
          263,
          265,
          267,
          274,
          276,
          282,
          285,
          288,
          292,
          302,
          303,
          304,
          305,
          307,
          311,
          312,
          320,
          322,
          323,
          329,
          331,
          335,
          339,
          341,
          343,
          355,
          371,
          377,
          381,
          393,
          397
         ],
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          23,
          31,
          34,
          37,
          38,
          41,
          47,
          60,
          67,
          74,
          75,
          81,
          94,
          99,
          101,
          102,
          105,
          107,
          108,
          111,
          113,
          114,
          116,
          118,
          119,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          131,
          133,
          136,
          138,
          139,
          141,
          145,
          146,
          147,
          149,
          151,
          152,
          155,
          157,
          158,
          161,
          163,
          164,
          165,
          167,
          169,
          170,
          171,
          173,
          175,
          177,
          179,
          182,
          183,
          184,
          186,
          187,
          189,
          191,
          192,
          193,
          196,
          199,
          200,
          201,
          202,
          204,
          206,
          208,
          210,
          211,
          212,
          213,
          219,
          220,
          221,
          224,
          227,
          228,
          231,
          232,
          235,
          237,
          239,
          241,
          242,
          244,
          246,
          247,
          248,
          253,
          258,
          260,
          263,
          265,
          267,
          274,
          276,
          282,
          285,
          288,
          292,
          302,
          303,
          304,
          305,
          307,
          311,
          312,
          320,
          322,
          323,
          329,
          331,
          335,
          339,
          341,
          343,
          355,
          371,
          377,
          381,
          393,
          397
         ],
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.927536231884058,
          0.9347826086956522,
          0.9347826086956522,
          0.9347826086956522,
          0.9347826086956522,
          0.9347826086956522,
          0.9347826086956522
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "autorange": true,
         "range": [
          -23.999118787451536,
          420.99911878745155
         ],
         "title": {
          "text": "#Trials"
         },
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "title": {
          "text": "Objective Value"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"96afc68a-0b67-45d9-bd6e-bed602259cf6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"96afc68a-0b67-45d9-bd6e-bed602259cf6\")) {                    Plotly.newPlot(                        \"96afc68a-0b67-45d9-bd6e-bed602259cf6\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"y\":[0.8913043478260869,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.927536231884058,0.9347826086956522,0.9347826086956522,0.9347826086956522,0.9347826086956522,0.9347826086956522,0.9347826086956522],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('96afc68a-0b67-45d9-bd6e-bed602259cf6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40,
           "y": 0.5
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.5804518520764872,
          0.5851132980949256,
          0.49482396969816944,
          0.46783554554661777,
          0.8898452351519299,
          0.4876396708210671,
          0.47141473283732505,
          0.45546039860403204,
          0.44086647271359114,
          0.4919119082396586,
          0.4840662000661084,
          0.4190191434337962,
          0.5511604953648286,
          0.5803842890896967,
          0.508919162261959,
          0.47025299899966616,
          0.48995453619863205,
          0.44146652559876187,
          0.5418940069459803,
          0.5461552177655429,
          0.5424440866525944,
          0.6104929555632567,
          0.5812400970273667,
          0.5763218663856007,
          0.6040044629604968,
          0.6068558779445329,
          0.599807675716334,
          0.5856340890929386,
          0.5681103326369603,
          0.5659398836571019,
          0.5338948394959222,
          0.5537051381165325,
          0.550068978639334,
          0.5593178504548724,
          0.5584178769664677,
          0.5609730012519499,
          0.5566477917365855,
          0.5839719089094231,
          0.5870176349566972,
          0.6485557868618289,
          0.6274049619170701,
          0.6569395345507714,
          0.5658964518889643,
          0.6479779136193088,
          0.6223026242856252,
          0.6369138011193989,
          0.6468477786997137,
          0.6568928981803261,
          0.5972013311347276,
          0.8211953128912031,
          0.7060373800050437,
          0.6807784072322954,
          0.7016661555840032,
          0.537696506233804,
          0.6022293358586384,
          0.6368081600870762,
          0.8467204478382204,
          0.8139947824520168,
          0.6165817308926591,
          0.8762961332194789,
          0.8679969292745693,
          0.9482363494904711,
          0.6999176615976964,
          0.9031108879706226,
          0.9474793879431477,
          0.9066604378484892,
          0.9476731543677575,
          0.9240260463003812,
          0.9061713382375294,
          0.9244771626651488,
          0.9195168044724182,
          0.949730752540515,
          0.8932513449858643,
          0.9175787632140546,
          0.9270209297706137,
          0.9351153859384567,
          0.9430899304209072,
          0.9497540462391896,
          0.9423946896772348,
          0.9179878705394965,
          0.9132549334195297,
          0.8917279584484489,
          0.9359269381384888,
          0.937247051797752,
          0.8914206312667102,
          0.9378116837589001,
          0.8929270479015202,
          0.9301174814449764,
          0.8948526150513979,
          0.9280581893238828,
          0.9302192930493405,
          0.9177303724306953,
          0.949741577636022,
          0.9206588775323452,
          0.9091306315625963,
          0.657262724453935,
          0.9239632598044228,
          0.9384914561973683,
          0.9350552712776203,
          0.9417568127889334,
          0.9428385489588795,
          0.9380135128153289,
          0.9385579472011139,
          0.9494116403022641,
          0.8885006746587057,
          0.6670164606670389,
          0.9358190493846237,
          0.657303631945503,
          0.9157468590942724,
          0.9331817274789793,
          0.8707251971573371,
          0.9324613460686108,
          0.9493824577281864,
          0.7249668989975571,
          0.9288505849674881,
          0.9253985696387867,
          0.6380007145934408,
          0.9371236052373733,
          0.9226226905243443,
          0.8898495569301608,
          0.930778621523237,
          0.883750164990119,
          0.9429428758293722,
          0.9498145228343837,
          0.9258838605940672,
          0.9492250141962931,
          0.8728497576464047,
          0.6458678488495863,
          0.8976912146414495,
          0.6321272780885892,
          0.8953156358244683,
          0.9026901998093335,
          0.9487273237632431,
          0.6495945474471355,
          0.6671674492231398,
          0.6159513800093103
         ],
         "xaxis": "x",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          6,
          0,
          3,
          1,
          6,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          7,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "xaxis": "x2",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8572213416136768,
          0.42440392873074434,
          0.6437658202709757,
          0.44249919078060934,
          0.47376017153710775,
          0.59151902806672,
          0.703482591976758,
          0.8752866581978932,
          0.7679021965499689,
          0.5950150628739558,
          0.47773610202820704,
          0.9223188508970734,
          0.842142292196655,
          0.5192456362986857,
          0.5688219119320554,
          0.5840602075355261,
          0.8504908684560342,
          0.6074504361300077,
          0.5010607343542013,
          0.4896676767052535,
          0.4935379697470976,
          0.45391544811386864,
          0.48020493814229687,
          0.47927297007830116,
          0.48627504773405517,
          0.4723201266618835,
          0.4666322673297106,
          0.42807756767644956,
          0.4255119050534043,
          0.43002460093512707,
          0.4674498825432342,
          0.4429309372711804,
          0.4666412262116455,
          0.4645081589497649,
          0.4408521671227798,
          0.46528170474978336,
          0.4414834038568922,
          0.4638474477254263,
          0.4565325341773345,
          0.4746031605317973,
          0.45847931312465756,
          0.43421547282953266,
          0.4587390809774395,
          0.4778733603265097,
          0.47460914242777663,
          0.4321845183824934,
          0.42675452875461306,
          0.4553942555039016,
          0.4553841872533177,
          0.4370038879877747,
          0.4645063684995525,
          0.44551936721684526,
          0.48257049332895985,
          0.4371630936855861,
          0.46563642821615786,
          0.42871084658785413,
          0.43635862139217435,
          0.45139322621058714,
          0.4683039127700122,
          0.43265171107892925,
          0.4316359011313908,
          0.4423887488706305,
          0.48364734585086305,
          0.4282461725712393,
          0.4545069298626002,
          0.45355782401588063,
          0.4238140478428581,
          0.4451362399390565,
          0.44598115586729153,
          0.45179768622556504,
          0.4556852963030598,
          0.45396123669642047,
          0.4364239122591324,
          0.4433138638550611,
          0.44650309814272005,
          0.4576436347063141,
          0.4593561959998612,
          0.4378198145647437,
          0.46200949848830325,
          0.4549712069044677,
          0.44596944784050785,
          0.4249684731601385,
          0.45325593234447603,
          0.4239569858581677,
          0.42598799222991124,
          0.4422178183893414,
          0.4305143569029505,
          0.4722109074051259,
          0.43346741245088427,
          0.4410278795285266,
          0.4389229129202197,
          0.45101483638921064,
          0.44562376416562605,
          0.4492681268517337,
          0.43716563789595975,
          0.4589210170068392,
          0.4557426891279983,
          0.4298109200351648,
          0.44841455460580754,
          0.439552743246341,
          0.4368088699785146,
          0.4289521822881538,
          0.4268726943123746,
          0.44649413830059886,
          0.4392388967209001,
          0.4574877159414479,
          0.45417670243793373,
          0.4740337023384668,
          0.440840569205368,
          0.45111239988398033,
          0.43502440374018925,
          0.42922394321430396,
          0.44111675923379845,
          0.44226154605940476,
          0.4447979407250257,
          0.4482089742427231,
          0.45457992715265605,
          0.46192087634616963,
          0.4420831122263088,
          0.4264677936345277,
          0.4496751930678758,
          0.4394967999444985,
          0.4244508473503001,
          0.49456035083583405,
          0.45678632502736394,
          0.44446470411495437,
          0.4349336008622563,
          0.42885533089087907,
          0.42694556945364565,
          0.4390294848631669,
          0.4242409093375889,
          0.4414778636241596,
          0.45061494837856014,
          0.4410085260515918,
          0.4334230786021242,
          0.4848077985521506
         ],
         "xaxis": "x3",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          5.248188772766292,
          3.6684956597588734,
          7.561023899833934,
          0.22846778566040865,
          7.649357604984371,
          0.8824066704552418,
          1.0568522814697778,
          1.9314431821524898,
          1.049432465606058,
          0.8054401023221277,
          1.9013029040400329,
          2.2766166531074092,
          1.0887907486617576,
          2.222642543975714,
          1.7496935863807828,
          1.62093641435582,
          0.8394165463689581,
          1.5808972668992203,
          1.782134748156407,
          2.644387422373428,
          5.457396595019099,
          2.203237491783856,
          2.2865950522856857,
          3.528972068219161,
          2.456579381777149,
          2.1231255668134503,
          2.124056056241013,
          2.1316481797849716,
          2.7785603485999695,
          3.3122688574407464,
          2.117831959262528,
          1.8978995871121078,
          2.1682002933224642,
          2.128735246148554,
          1.4729619397787206,
          1.4960385539772352,
          1.5172581963822895,
          2.0704231829830606,
          1.7406521223953868,
          2.2139077080783904,
          2.0012504481446203,
          2.1518547274967603,
          1.9011515918030348,
          2.9574418373945863,
          2.9917332338962455,
          2.934366953851249,
          2.5358103478039014,
          3.0858328127824954,
          3.190074666618986,
          1.66734349205634,
          3.4362561955680393,
          3.77723880290995,
          2.9633034979365913,
          2.369451674646884,
          2.0874965143705086,
          2.5243922112400985,
          2.6886050854554275,
          3.5710458242906666,
          2.248094548216824,
          2.500922737067342,
          2.9566016906708645,
          1.4072090284667538,
          3.798669169634183,
          2.7735080011297573,
          3.0120444970253875,
          2.6543121777355223,
          3.211660584285087,
          3.2009836489601295,
          4.178380367937791,
          3.2348800346394535,
          3.0423789760271682,
          3.2437835298165925,
          2.6024579636861542,
          3.084520342143333,
          3.2593779187536938,
          2.9160002753394316,
          2.934549185974688,
          2.8845662178338354,
          2.986733824006981,
          3.429617666178896,
          3.135693423898013,
          2.8561770348531055,
          3.474425660014476,
          2.8252866727755777,
          2.8718494134926424,
          2.67725483763729,
          2.5897596121856727,
          2.8945928639163068,
          2.6748995201232204,
          2.6802992055090864,
          2.9129222512178523,
          3.2670259863869817,
          3.187442794254875,
          3.4481606480953504,
          2.6779562888379944,
          2.5103332730667605,
          3.4104722100676543,
          2.732900897345977,
          3.4809713896652297,
          2.642122126072374,
          3.606215015631592,
          2.902410076002463,
          2.8364110377636678,
          3.0451605061069023,
          2.6672504776150645,
          3.0344976702340873,
          3.744622656285927,
          1.9353828000119515,
          3.2413635949859367,
          3.586940941877024,
          2.484886328889485,
          2.700706070879852,
          2.6675738796088884,
          2.8077847065168378,
          3.226325607677646,
          3.1517471179315173,
          2.56643690852696,
          3.3530680039456295,
          3.3084977064701553,
          2.7592553011940244,
          3.560673819057762,
          2.719884290569974,
          3.1082782278366237,
          2.1126521521992476,
          3.407416179098802,
          3.096691925995637,
          2.7340086766883465,
          2.4943713551506503,
          2.6621695088489687,
          3.09571028397168,
          2.6763226060961807,
          3.148959569282457,
          2.9139587914727,
          2.3696904287963,
          2.8846505614513642,
          2.4209843879205906
         ],
         "xaxis": "x4",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          4.417575470998656,
          2.596662509590846,
          7.165858687539752,
          8.726289100063267,
          1.5092378534474686,
          8.227163906913553,
          8.587470161122868,
          9.101006404930581,
          9.91261210726734,
          8.381602928408405,
          8.56858892752752,
          9.238607082341131,
          9.529525605481567,
          9.51716672665794,
          7.162210941655427,
          7.987624084641333,
          9.172043661071438,
          8.880870946382874,
          5.434126332720901,
          5.211953537557605,
          5.070290581717602,
          5.637259558559115,
          5.586367384360327,
          5.464418116591806,
          4.359111360611379,
          4.001911613797047,
          3.9930929102837243,
          3.251561934071465,
          2.256015115079869,
          2.3439435175295404,
          1.7906167270772206,
          1.7094694222445372,
          1.7955276162774851,
          1.7466439428057448,
          1.7160777486726384,
          1.620860358381152,
          1.849897381540938,
          1.2757841033985309,
          1.3984651447909593,
          2.201536907006279,
          1.7388890361069362,
          2.932468872747237,
          1.679998483228158,
          1.186701514137045,
          1.1800833072136256,
          0.6681707270248475,
          2.877308644552227,
          1.1079677599141249,
          1.0124707422074508,
          1.4773645674346636,
          1.0399603399932391,
          1.7329122568124533,
          1.1578114304617957,
          1.8233345828170737,
          3.334011665976792,
          0.9447003036686734,
          1.5110411441340044,
          1.3510484686220612,
          2.027513147551977,
          0.9835239087131857,
          0.8534907383909056,
          1.8390726765634686,
          1.1540929863194078,
          1.351932374993338,
          1.3592746166539005,
          1.3828342698513623,
          1.3925534219324491,
          0.6463628568329032,
          0.5602698901750998,
          1.3158766982011572,
          1.2733852277630389,
          1.0520131819440255,
          1.244996744597576,
          0.8233878492754836,
          1.2671146466630867,
          0.5792339141940959,
          0.02876347721076189,
          0.6328652812671767,
          0.462840608430276,
          0.40676277061318017,
          0.3935970446191328,
          0.6664898893067663,
          0.4816018956891892,
          0.7517781461800804,
          0.7121295812942449,
          0.5944173663086032,
          0.8459892642982725,
          0.22250509201899404,
          0.8490689613979071,
          1.5213741348801806,
          1.7916082276707617,
          0.6100867465160481,
          1.0658098314944104,
          0.39250812096602145,
          0.9575540643772347,
          1.9665904313727864,
          0.5796970766359173,
          1.2609027767861198,
          0.43819966551021056,
          0.9048728046018102,
          0.46757001141356713,
          0.8305889303874784,
          0.8855792691810711,
          0.3138947958826373,
          0.7306963050130332,
          1.7641578312145108,
          0.5438282589513714,
          1.4829985158093906,
          0.24635169489518177,
          0.48939733810401276,
          0.00040895783028454397,
          1.0816711236544747,
          1.0180089636943075,
          1.1212811802529155,
          1.1103569830097042,
          1.2105607185342044,
          0.6801323035651516,
          0.45790134276894734,
          5.754969914069346,
          0.9047973261495865,
          0.3998092612386865,
          0.5724154868748197,
          1.1638790963837895,
          2.168807717492318,
          0.8625796485643731,
          1.475544639675966,
          1.4869145893340738,
          0.8871763509206548,
          0.8701965646827093,
          0.9597124263021729,
          0.9195667832149104,
          1.500812405967225,
          1.5583429759814282,
          1.725264247467216,
          1.676981456822331,
          5.326915476416813
         ],
         "xaxis": "x5",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.38985392008200753,
          0.14736629800897433,
          0.4095057582701581,
          0.3034681868738094,
          0.4219027230701271,
          0.32391323969556035,
          0.32445061549022125,
          0.4434005855106946,
          0.35605059798611816,
          0.3218077088259798,
          0.31047979530096925,
          0.4148549514462878,
          0.37084400501854764,
          0.3998702933128024,
          0.343473728890272,
          0.4456427862287087,
          0.355021923179271,
          0.4342585606389763,
          0.4500395344145942,
          0.425721639357535,
          0.42937724793408066,
          0.49757812791201117,
          0.4782230221850683,
          0.44219621877938087,
          0.49920182805249647,
          0.4581630022908588,
          0.48683823201022147,
          0.46323339882663145,
          0.4671878869360155,
          0.46682540036712916,
          0.4715506636737873,
          0.45825707459208953,
          0.47487798045426005,
          0.4717046469692084,
          0.47242097511686054,
          0.47387801562740495,
          0.46887078617660116,
          0.4867806623890821,
          0.4820125799146437,
          0.4563930785927296,
          0.4722609849930033,
          0.44695790232725513,
          0.47108830862397677,
          0.43713245107775117,
          0.43806180871404954,
          0.43811375564660526,
          0.45152666323608504,
          0.44178939584024707,
          0.4833419811638725,
          0.41990820416612246,
          0.4731590898227775,
          0.47499566140613836,
          0.45667211752764214,
          0.47269940737255306,
          0.49019024756541874,
          0.4647176847965696,
          0.4218971427728908,
          0.43898371845767115,
          0.4821067092802648,
          0.4227469785346675,
          0.4062789509696708,
          0.4763179935478219,
          0.49544394672638137,
          0.44006514453025786,
          0.4471344763763018,
          0.44463715803096066,
          0.4286718148566089,
          0.43078242100027375,
          0.43134767742326036,
          0.42931165695922063,
          0.4465988372506536,
          0.4484527717897264,
          0.4136521457434043,
          0.4309176949087885,
          0.4470583255168543,
          0.42213123723375434,
          0.43704790257354453,
          0.44113616461124633,
          0.4213903786763416,
          0.42026140240703325,
          0.4152639612114153,
          0.43630315191599356,
          0.41640943165980215,
          0.4349373571759066,
          0.43619205142544204,
          0.4326520816907943,
          0.45024925981428526,
          0.3995888751732796,
          0.4418373472627024,
          0.43451520249319425,
          0.4619463081954937,
          0.42809960629828736,
          0.4369598008777899,
          0.41178966336552597,
          0.41980877034037833,
          0.44247813053117496,
          0.42765603530670065,
          0.43587961992708646,
          0.42459013614970975,
          0.4342971061631148,
          0.4060446105875929,
          0.42211294089088386,
          0.4229080633644974,
          0.4009449373295211,
          0.4117562363617219,
          0.44744975047915403,
          0.38612914386795383,
          0.4651168341350098,
          0.4453943818347651,
          0.4209090373626143,
          0.4110316888871964,
          0.4366168729413608,
          0.43929403121951294,
          0.4222046215122603,
          0.43722817885257376,
          0.4400576291730056,
          0.44814229835119235,
          0.41796198228044934,
          0.43172397224553416,
          0.4061207621194904,
          0.4190788655217431,
          0.4564202722174788,
          0.43857703938522496,
          0.4589660372882733,
          0.44148178553412015,
          0.4331186455130454,
          0.44589638292756345,
          0.45961885615902665,
          0.4433536794363946,
          0.44702353101976383,
          0.44014139535340124,
          0.4577728989866053,
          0.42645493484453095,
          0.4306684847658824,
          0.4448382382359521,
          0.4906505881790144
         ],
         "xaxis": "x6",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          10,
          9,
          9,
          6,
          10,
          8,
          8,
          9,
          6,
          8,
          7,
          6,
          9,
          7,
          8,
          8,
          6,
          8,
          8,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10
         ],
         "xaxis": "x7",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          69,
          41,
          75,
          47,
          44,
          67,
          72,
          50,
          56,
          67,
          73,
          78,
          88,
          65,
          66,
          71,
          47,
          65,
          75,
          64,
          63,
          47,
          39,
          40,
          38,
          45,
          34,
          43,
          43,
          42,
          49,
          50,
          49,
          49,
          49,
          48,
          49,
          52,
          39,
          52,
          45,
          45,
          49,
          53,
          47,
          46,
          53,
          47,
          41,
          47,
          48,
          50,
          45,
          49,
          46,
          43,
          47,
          47,
          51,
          47,
          48,
          49,
          46,
          51,
          51,
          44,
          43,
          51,
          51,
          40,
          48,
          42,
          45,
          51,
          49,
          47,
          47,
          46,
          44,
          43,
          45,
          51,
          43,
          38,
          38,
          51,
          53,
          49,
          52,
          46,
          45,
          40,
          51,
          42,
          46,
          50,
          42,
          48,
          43,
          46,
          43,
          45,
          45,
          43,
          46,
          40,
          42,
          44,
          44,
          42,
          46,
          43,
          52,
          48,
          47,
          41,
          47,
          45,
          52,
          52,
          41,
          52,
          47,
          48,
          43,
          46,
          50,
          49,
          51,
          45,
          52,
          44,
          46,
          46,
          46,
          47
         ],
         "xaxis": "x8",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y8"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          836,
          744,
          149,
          574,
          144,
          642,
          671,
          529,
          738,
          479,
          658,
          796,
          790,
          669,
          643,
          841,
          712,
          470,
          266,
          227,
          223,
          190,
          248,
          232,
          173,
          171,
          159,
          204,
          142,
          136,
          166,
          152,
          155,
          155,
          160,
          151,
          123,
          159,
          129,
          151,
          127,
          142,
          126,
          115,
          113,
          111,
          177,
          119,
          119,
          124,
          147,
          152,
          111,
          100,
          167,
          182,
          120,
          128,
          160,
          122,
          123,
          117,
          112,
          117,
          100,
          117,
          117,
          116,
          116,
          108,
          118,
          105,
          122,
          108,
          105,
          114,
          115,
          117,
          110,
          116,
          115,
          127,
          108,
          125,
          124,
          116,
          142,
          130,
          133,
          120,
          104,
          115,
          116,
          108,
          124,
          128,
          117,
          107,
          108,
          125,
          123,
          100,
          101,
          114,
          121,
          111,
          115,
          132,
          118,
          100,
          136,
          121,
          124,
          120,
          125,
          113,
          126,
          314,
          117,
          124,
          108,
          124,
          120,
          130,
          111,
          114,
          120,
          145,
          133,
          105,
          133,
          114,
          116,
          135,
          139,
          118
         ],
         "xaxis": "x9",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y9"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           23,
           31,
           34,
           37,
           38,
           41,
           47,
           60,
           67,
           74,
           75,
           81,
           94,
           99,
           101,
           102,
           105,
           107,
           108,
           111,
           113,
           114,
           116,
           118,
           119,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           131,
           133,
           136,
           138,
           139,
           141,
           145,
           146,
           147,
           149,
           151,
           152,
           155,
           157,
           158,
           161,
           163,
           164,
           165,
           167,
           169,
           170,
           171,
           173,
           175,
           177,
           179,
           182,
           183,
           184,
           186,
           187,
           189,
           191,
           192,
           193,
           196,
           199,
           200,
           201,
           202,
           204,
           206,
           208,
           210,
           211,
           212,
           213,
           219,
           220,
           221,
           224,
           227,
           228,
           231,
           232,
           235,
           237,
           239,
           241,
           242,
           244,
           246,
           247,
           248,
           253,
           258,
           260,
           263,
           265,
           267,
           274,
           276,
           282,
           285,
           288,
           292,
           302,
           303,
           304,
           305,
           307,
           311,
           312,
           320,
           322,
           323,
           329,
           331,
           335,
           339,
           341,
           343,
           355,
           371,
           377,
           381,
           393,
           397
          ],
          "colorbar": {
           "title": {
            "text": "#Trials"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          165,
          159,
          17,
          163,
          42,
          176,
          174,
          194,
          204,
          175,
          173,
          212,
          219,
          212,
          191,
          181,
          155,
          191,
          185,
          211,
          219,
          155,
          189,
          181,
          213,
          17,
          32,
          24,
          32,
          22,
          31,
          29,
          30,
          44,
          47,
          47,
          51,
          28,
          48,
          40,
          28,
          8,
          48,
          39,
          36,
          37,
          40,
          56,
          25,
          55,
          43,
          58,
          38,
          45,
          29,
          12,
          29,
          55,
          8,
          29,
          50,
          36,
          34,
          37,
          38,
          14,
          114,
          13,
          15,
          13,
          21,
          121,
          15,
          19,
          37,
          9,
          14,
          19,
          19,
          13,
          14,
          21,
          8,
          21,
          21,
          16,
          88,
          28,
          38,
          19,
          22,
          13,
          9,
          13,
          37,
          18,
          13,
          14,
          12,
          46,
          47,
          43,
          39,
          8,
          95,
          15,
          14,
          29,
          13,
          36,
          37,
          22,
          37,
          42,
          37,
          12,
          38,
          8,
          17,
          39,
          17,
          89,
          9,
          29,
          15,
          17,
          39,
          42,
          41,
          9,
          38,
          253,
          18,
          37,
          37,
          43
         ],
         "xaxis": "x10",
         "y": [
          0.8913043478260869,
          0.8985507246376812,
          0.8768115942028986,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.8913043478260869,
          0.8985507246376812,
          0.8913043478260869,
          0.8768115942028986,
          0.9057971014492754,
          0.8840579710144928,
          0.8768115942028986,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8768115942028986,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.8913043478260869,
          0.9202898550724637,
          0.8913043478260869,
          0.9057971014492754,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.8985507246376812,
          0.927536231884058,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9202898550724637,
          0.9130434782608695,
          0.8840579710144928,
          0.9130434782608695,
          0.9057971014492754,
          0.8913043478260869,
          0.9202898550724637,
          0.9057971014492754,
          0.8985507246376812,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9202898550724637,
          0.9202898550724637,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.9130434782608695,
          0.8840579710144928,
          0.9057971014492754,
          0.8985507246376812,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.9202898550724637,
          0.9057971014492754,
          0.9202898550724637,
          0.9057971014492754,
          0.9057971014492754,
          0.9130434782608695,
          0.8913043478260869,
          0.8985507246376812,
          0.9057971014492754,
          0.9057971014492754,
          0.9202898550724637,
          0.9130434782608695,
          0.8985507246376812,
          0.9057971014492754,
          0.9130434782608695,
          0.927536231884058,
          0.9130434782608695,
          0.9130434782608695,
          0.9347826086956522,
          0.8985507246376812,
          0.9130434782608695,
          0.9130434782608695,
          0.8985507246376812,
          0.9130434782608695
         ],
         "yaxis": "y10"
        }
       ],
       "layout": {
        "autosize": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          0.082
         ],
         "range": [
          0.3553738999267766,
          1.0134597663414033
         ],
         "title": {
          "text": "bagging_fraction"
         },
         "type": "linear"
        },
        "xaxis10": {
         "anchor": "y10",
         "autorange": true,
         "domain": [
          0.9179999999999999,
          0.9999999999999999
         ],
         "range": [
          -21.3768281796813,
          282.3768281796813
         ],
         "title": {
          "text": "num_leaves"
         },
         "type": "linear"
        },
        "xaxis2": {
         "anchor": "y2",
         "autorange": true,
         "domain": [
          0.10200000000000001,
          0.184
         ],
         "range": [
          -0.8393379479908945,
          7.839337947990894
         ],
         "title": {
          "text": "bagging_freq"
         },
         "type": "linear"
        },
        "xaxis3": {
         "anchor": "y3",
         "autorange": true,
         "domain": [
          0.20400000000000001,
          0.28600000000000003
         ],
         "range": [
          0.3640406194915538,
          0.9820922792483777
         ],
         "title": {
          "text": "feature_fraction"
         },
         "type": "linear"
        },
        "xaxis4": {
         "anchor": "y4",
         "autorange": true,
         "domain": [
          0.306,
          0.388
         ],
         "range": [
          -0.661337133370719,
          8.539162524015499
         ],
         "title": {
          "text": "lambda_l1"
         },
         "type": "linear"
        },
        "xaxis5": {
         "anchor": "y5",
         "autorange": true,
         "domain": [
          0.40800000000000003,
          0.49000000000000005
         ],
         "range": [
          -1.1881179352436264,
          11.10113900034125
         ],
         "title": {
          "text": "lambda_l2"
         },
         "type": "linear"
        },
        "xaxis6": {
         "anchor": "y6",
         "autorange": true,
         "domain": [
          0.51,
          0.592
         ],
         "range": [
          0.1051793106065431,
          0.5413888154549277
         ],
         "title": {
          "text": "learning_rate"
         },
         "type": "linear"
        },
        "xaxis7": {
         "anchor": "y7",
         "autorange": true,
         "domain": [
          0.6120000000000001,
          0.6940000000000001
         ],
         "range": [
          5.520378315433774,
          10.479621684566226
         ],
         "title": {
          "text": "max_depth"
         },
         "type": "linear"
        },
        "xaxis8": {
         "anchor": "y8",
         "autorange": true,
         "domain": [
          0.7140000000000001,
          0.796
         ],
         "range": [
          27.52510725835596,
          94.47489274164404
         ],
         "title": {
          "text": "min_child_samples"
         },
         "type": "linear"
        },
        "xaxis9": {
         "anchor": "y9",
         "autorange": true,
         "domain": [
          0.8160000000000001,
          0.898
         ],
         "range": [
          11.150082934106749,
          929.8499170658932
         ],
         "title": {
          "text": "n_estimators"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "title": {
          "text": "Objective Value"
         },
         "type": "linear"
        },
        "yaxis10": {
         "anchor": "x10",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis2": {
         "anchor": "x2",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis3": {
         "anchor": "x3",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis4": {
         "anchor": "x4",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis5": {
         "anchor": "x5",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis6": {
         "anchor": "x6",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis7": {
         "anchor": "x7",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis8": {
         "anchor": "x8",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis9": {
         "anchor": "x9",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "range": [
          0.872565309701837,
          0.9390288931967138
         ],
         "showticklabels": false,
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6b682b52-b655-4da0-99f6-209bc3bbb5b3\" class=\"plotly-graph-div\" style=\"height:525px; width:3000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b682b52-b655-4da0-99f6-209bc3bbb5b3\")) {                    Plotly.newPlot(                        \"6b682b52-b655-4da0-99f6-209bc3bbb5b3\",                        [{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.5804518520764872,0.5851132980949256,0.49482396969816944,0.46783554554661777,0.8898452351519299,0.4876396708210671,0.47141473283732505,0.45546039860403204,0.44086647271359114,0.4919119082396586,0.4840662000661084,0.4190191434337962,0.5511604953648286,0.5803842890896967,0.508919162261959,0.47025299899966616,0.48995453619863205,0.44146652559876187,0.5418940069459803,0.5461552177655429,0.5424440866525944,0.6104929555632567,0.5812400970273667,0.5763218663856007,0.6040044629604968,0.6068558779445329,0.599807675716334,0.5856340890929386,0.5681103326369603,0.5659398836571019,0.5338948394959222,0.5537051381165325,0.550068978639334,0.5593178504548724,0.5584178769664677,0.5609730012519499,0.5566477917365855,0.5839719089094231,0.5870176349566972,0.6485557868618289,0.6274049619170701,0.6569395345507714,0.5658964518889643,0.6479779136193088,0.6223026242856252,0.6369138011193989,0.6468477786997137,0.6568928981803261,0.5972013311347276,0.8211953128912031,0.7060373800050437,0.6807784072322954,0.7016661555840032,0.537696506233804,0.6022293358586384,0.6368081600870762,0.8467204478382204,0.8139947824520168,0.6165817308926591,0.8762961332194789,0.8679969292745693,0.9482363494904711,0.6999176615976964,0.9031108879706226,0.9474793879431477,0.9066604378484892,0.9476731543677575,0.9240260463003812,0.9061713382375294,0.9244771626651488,0.9195168044724182,0.949730752540515,0.8932513449858643,0.9175787632140546,0.9270209297706137,0.9351153859384567,0.9430899304209072,0.9497540462391896,0.9423946896772348,0.9179878705394965,0.9132549334195297,0.8917279584484489,0.9359269381384888,0.937247051797752,0.8914206312667102,0.9378116837589001,0.8929270479015202,0.9301174814449764,0.8948526150513979,0.9280581893238828,0.9302192930493405,0.9177303724306953,0.949741577636022,0.9206588775323452,0.9091306315625963,0.657262724453935,0.9239632598044228,0.9384914561973683,0.9350552712776203,0.9417568127889334,0.9428385489588795,0.9380135128153289,0.9385579472011139,0.9494116403022641,0.8885006746587057,0.6670164606670389,0.9358190493846237,0.657303631945503,0.9157468590942724,0.9331817274789793,0.8707251971573371,0.9324613460686108,0.9493824577281864,0.7249668989975571,0.9288505849674881,0.9253985696387867,0.6380007145934408,0.9371236052373733,0.9226226905243443,0.8898495569301608,0.930778621523237,0.883750164990119,0.9429428758293722,0.9498145228343837,0.9258838605940672,0.9492250141962931,0.8728497576464047,0.6458678488495863,0.8976912146414495,0.6321272780885892,0.8953156358244683,0.9026901998093335,0.9487273237632431,0.6495945474471355,0.6671674492231398,0.6159513800093103],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[6,0,3,1,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.8572213416136768,0.42440392873074434,0.6437658202709757,0.44249919078060934,0.47376017153710775,0.59151902806672,0.703482591976758,0.8752866581978932,0.7679021965499689,0.5950150628739558,0.47773610202820704,0.9223188508970734,0.842142292196655,0.5192456362986857,0.5688219119320554,0.5840602075355261,0.8504908684560342,0.6074504361300077,0.5010607343542013,0.4896676767052535,0.4935379697470976,0.45391544811386864,0.48020493814229687,0.47927297007830116,0.48627504773405517,0.4723201266618835,0.4666322673297106,0.42807756767644956,0.4255119050534043,0.43002460093512707,0.4674498825432342,0.4429309372711804,0.4666412262116455,0.4645081589497649,0.4408521671227798,0.46528170474978336,0.4414834038568922,0.4638474477254263,0.4565325341773345,0.4746031605317973,0.45847931312465756,0.43421547282953266,0.4587390809774395,0.4778733603265097,0.47460914242777663,0.4321845183824934,0.42675452875461306,0.4553942555039016,0.4553841872533177,0.4370038879877747,0.4645063684995525,0.44551936721684526,0.48257049332895985,0.4371630936855861,0.46563642821615786,0.42871084658785413,0.43635862139217435,0.45139322621058714,0.4683039127700122,0.43265171107892925,0.4316359011313908,0.4423887488706305,0.48364734585086305,0.4282461725712393,0.4545069298626002,0.45355782401588063,0.4238140478428581,0.4451362399390565,0.44598115586729153,0.45179768622556504,0.4556852963030598,0.45396123669642047,0.4364239122591324,0.4433138638550611,0.44650309814272005,0.4576436347063141,0.4593561959998612,0.4378198145647437,0.46200949848830325,0.4549712069044677,0.44596944784050785,0.4249684731601385,0.45325593234447603,0.4239569858581677,0.42598799222991124,0.4422178183893414,0.4305143569029505,0.4722109074051259,0.43346741245088427,0.4410278795285266,0.4389229129202197,0.45101483638921064,0.44562376416562605,0.4492681268517337,0.43716563789595975,0.4589210170068392,0.4557426891279983,0.4298109200351648,0.44841455460580754,0.439552743246341,0.4368088699785146,0.4289521822881538,0.4268726943123746,0.44649413830059886,0.4392388967209001,0.4574877159414479,0.45417670243793373,0.4740337023384668,0.440840569205368,0.45111239988398033,0.43502440374018925,0.42922394321430396,0.44111675923379845,0.44226154605940476,0.4447979407250257,0.4482089742427231,0.45457992715265605,0.46192087634616963,0.4420831122263088,0.4264677936345277,0.4496751930678758,0.4394967999444985,0.4244508473503001,0.49456035083583405,0.45678632502736394,0.44446470411495437,0.4349336008622563,0.42885533089087907,0.42694556945364565,0.4390294848631669,0.4242409093375889,0.4414778636241596,0.45061494837856014,0.4410085260515918,0.4334230786021242,0.4848077985521506],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[5.248188772766292,3.6684956597588734,7.561023899833934,0.22846778566040865,7.649357604984371,0.8824066704552418,1.0568522814697778,1.9314431821524898,1.049432465606058,0.8054401023221277,1.9013029040400329,2.2766166531074092,1.0887907486617576,2.222642543975714,1.7496935863807828,1.62093641435582,0.8394165463689581,1.5808972668992203,1.782134748156407,2.644387422373428,5.457396595019099,2.203237491783856,2.2865950522856857,3.528972068219161,2.456579381777149,2.1231255668134503,2.124056056241013,2.1316481797849716,2.7785603485999695,3.3122688574407464,2.117831959262528,1.8978995871121078,2.1682002933224642,2.128735246148554,1.4729619397787206,1.4960385539772352,1.5172581963822895,2.0704231829830606,1.7406521223953868,2.2139077080783904,2.0012504481446203,2.1518547274967603,1.9011515918030348,2.9574418373945863,2.9917332338962455,2.934366953851249,2.5358103478039014,3.0858328127824954,3.190074666618986,1.66734349205634,3.4362561955680393,3.77723880290995,2.9633034979365913,2.369451674646884,2.0874965143705086,2.5243922112400985,2.6886050854554275,3.5710458242906666,2.248094548216824,2.500922737067342,2.9566016906708645,1.4072090284667538,3.798669169634183,2.7735080011297573,3.0120444970253875,2.6543121777355223,3.211660584285087,3.2009836489601295,4.178380367937791,3.2348800346394535,3.0423789760271682,3.2437835298165925,2.6024579636861542,3.084520342143333,3.2593779187536938,2.9160002753394316,2.934549185974688,2.8845662178338354,2.986733824006981,3.429617666178896,3.135693423898013,2.8561770348531055,3.474425660014476,2.8252866727755777,2.8718494134926424,2.67725483763729,2.5897596121856727,2.8945928639163068,2.6748995201232204,2.6802992055090864,2.9129222512178523,3.2670259863869817,3.187442794254875,3.4481606480953504,2.6779562888379944,2.5103332730667605,3.4104722100676543,2.732900897345977,3.4809713896652297,2.642122126072374,3.606215015631592,2.902410076002463,2.8364110377636678,3.0451605061069023,2.6672504776150645,3.0344976702340873,3.744622656285927,1.9353828000119515,3.2413635949859367,3.586940941877024,2.484886328889485,2.700706070879852,2.6675738796088884,2.8077847065168378,3.226325607677646,3.1517471179315173,2.56643690852696,3.3530680039456295,3.3084977064701553,2.7592553011940244,3.560673819057762,2.719884290569974,3.1082782278366237,2.1126521521992476,3.407416179098802,3.096691925995637,2.7340086766883465,2.4943713551506503,2.6621695088489687,3.09571028397168,2.6763226060961807,3.148959569282457,2.9139587914727,2.3696904287963,2.8846505614513642,2.4209843879205906],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[4.417575470998656,2.596662509590846,7.165858687539752,8.726289100063267,1.5092378534474686,8.227163906913553,8.587470161122868,9.101006404930581,9.91261210726734,8.381602928408405,8.56858892752752,9.238607082341131,9.529525605481567,9.51716672665794,7.162210941655427,7.987624084641333,9.172043661071438,8.880870946382874,5.434126332720901,5.211953537557605,5.070290581717602,5.637259558559115,5.586367384360327,5.464418116591806,4.359111360611379,4.001911613797047,3.9930929102837243,3.251561934071465,2.256015115079869,2.3439435175295404,1.7906167270772206,1.7094694222445372,1.7955276162774851,1.7466439428057448,1.7160777486726384,1.620860358381152,1.849897381540938,1.2757841033985309,1.3984651447909593,2.201536907006279,1.7388890361069362,2.932468872747237,1.679998483228158,1.186701514137045,1.1800833072136256,0.6681707270248475,2.877308644552227,1.1079677599141249,1.0124707422074508,1.4773645674346636,1.0399603399932391,1.7329122568124533,1.1578114304617957,1.8233345828170737,3.334011665976792,0.9447003036686734,1.5110411441340044,1.3510484686220612,2.027513147551977,0.9835239087131857,0.8534907383909056,1.8390726765634686,1.1540929863194078,1.351932374993338,1.3592746166539005,1.3828342698513623,1.3925534219324491,0.6463628568329032,0.5602698901750998,1.3158766982011572,1.2733852277630389,1.0520131819440255,1.244996744597576,0.8233878492754836,1.2671146466630867,0.5792339141940959,0.02876347721076189,0.6328652812671767,0.462840608430276,0.40676277061318017,0.3935970446191328,0.6664898893067663,0.4816018956891892,0.7517781461800804,0.7121295812942449,0.5944173663086032,0.8459892642982725,0.22250509201899404,0.8490689613979071,1.5213741348801806,1.7916082276707617,0.6100867465160481,1.0658098314944104,0.39250812096602145,0.9575540643772347,1.9665904313727864,0.5796970766359173,1.2609027767861198,0.43819966551021056,0.9048728046018102,0.46757001141356713,0.8305889303874784,0.8855792691810711,0.3138947958826373,0.7306963050130332,1.7641578312145108,0.5438282589513714,1.4829985158093906,0.24635169489518177,0.48939733810401276,0.00040895783028454397,1.0816711236544747,1.0180089636943075,1.1212811802529155,1.1103569830097042,1.2105607185342044,0.6801323035651516,0.45790134276894734,5.754969914069346,0.9047973261495865,0.3998092612386865,0.5724154868748197,1.1638790963837895,2.168807717492318,0.8625796485643731,1.475544639675966,1.4869145893340738,0.8871763509206548,0.8701965646827093,0.9597124263021729,0.9195667832149104,1.500812405967225,1.5583429759814282,1.725264247467216,1.676981456822331,5.326915476416813],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.38985392008200753,0.14736629800897433,0.4095057582701581,0.3034681868738094,0.4219027230701271,0.32391323969556035,0.32445061549022125,0.4434005855106946,0.35605059798611816,0.3218077088259798,0.31047979530096925,0.4148549514462878,0.37084400501854764,0.3998702933128024,0.343473728890272,0.4456427862287087,0.355021923179271,0.4342585606389763,0.4500395344145942,0.425721639357535,0.42937724793408066,0.49757812791201117,0.4782230221850683,0.44219621877938087,0.49920182805249647,0.4581630022908588,0.48683823201022147,0.46323339882663145,0.4671878869360155,0.46682540036712916,0.4715506636737873,0.45825707459208953,0.47487798045426005,0.4717046469692084,0.47242097511686054,0.47387801562740495,0.46887078617660116,0.4867806623890821,0.4820125799146437,0.4563930785927296,0.4722609849930033,0.44695790232725513,0.47108830862397677,0.43713245107775117,0.43806180871404954,0.43811375564660526,0.45152666323608504,0.44178939584024707,0.4833419811638725,0.41990820416612246,0.4731590898227775,0.47499566140613836,0.45667211752764214,0.47269940737255306,0.49019024756541874,0.4647176847965696,0.4218971427728908,0.43898371845767115,0.4821067092802648,0.4227469785346675,0.4062789509696708,0.4763179935478219,0.49544394672638137,0.44006514453025786,0.4471344763763018,0.44463715803096066,0.4286718148566089,0.43078242100027375,0.43134767742326036,0.42931165695922063,0.4465988372506536,0.4484527717897264,0.4136521457434043,0.4309176949087885,0.4470583255168543,0.42213123723375434,0.43704790257354453,0.44113616461124633,0.4213903786763416,0.42026140240703325,0.4152639612114153,0.43630315191599356,0.41640943165980215,0.4349373571759066,0.43619205142544204,0.4326520816907943,0.45024925981428526,0.3995888751732796,0.4418373472627024,0.43451520249319425,0.4619463081954937,0.42809960629828736,0.4369598008777899,0.41178966336552597,0.41980877034037833,0.44247813053117496,0.42765603530670065,0.43587961992708646,0.42459013614970975,0.4342971061631148,0.4060446105875929,0.42211294089088386,0.4229080633644974,0.4009449373295211,0.4117562363617219,0.44744975047915403,0.38612914386795383,0.4651168341350098,0.4453943818347651,0.4209090373626143,0.4110316888871964,0.4366168729413608,0.43929403121951294,0.4222046215122603,0.43722817885257376,0.4400576291730056,0.44814229835119235,0.41796198228044934,0.43172397224553416,0.4061207621194904,0.4190788655217431,0.4564202722174788,0.43857703938522496,0.4589660372882733,0.44148178553412015,0.4331186455130454,0.44589638292756345,0.45961885615902665,0.4433536794363946,0.44702353101976383,0.44014139535340124,0.4577728989866053,0.42645493484453095,0.4306684847658824,0.4448382382359521,0.4906505881790144],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[10,9,9,6,10,8,8,9,6,8,7,6,9,7,8,8,6,8,8,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,9,10,10,10,10,10,10,10,10],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[69,41,75,47,44,67,72,50,56,67,73,78,88,65,66,71,47,65,75,64,63,47,39,40,38,45,34,43,43,42,49,50,49,49,49,48,49,52,39,52,45,45,49,53,47,46,53,47,41,47,48,50,45,49,46,43,47,47,51,47,48,49,46,51,51,44,43,51,51,40,48,42,45,51,49,47,47,46,44,43,45,51,43,38,38,51,53,49,52,46,45,40,51,42,46,50,42,48,43,46,43,45,45,43,46,40,42,44,44,42,46,43,52,48,47,41,47,45,52,52,41,52,47,48,43,46,50,49,51,45,52,44,46,46,46,47],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[836,744,149,574,144,642,671,529,738,479,658,796,790,669,643,841,712,470,266,227,223,190,248,232,173,171,159,204,142,136,166,152,155,155,160,151,123,159,129,151,127,142,126,115,113,111,177,119,119,124,147,152,111,100,167,182,120,128,160,122,123,117,112,117,100,117,117,116,116,108,118,105,122,108,105,114,115,117,110,116,115,127,108,125,124,116,142,130,133,120,104,115,116,108,124,128,117,107,108,125,123,100,101,114,121,111,115,132,118,100,136,121,124,120,125,113,126,314,117,124,108,124,120,130,111,114,120,145,133,105,133,114,116,135,139,118],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"color\":[0,1,2,3,4,23,31,34,37,38,41,47,60,67,74,75,81,94,99,101,102,105,107,108,111,113,114,116,118,119,121,122,123,124,125,126,127,131,133,136,138,139,141,145,146,147,149,151,152,155,157,158,161,163,164,165,167,169,170,171,173,175,177,179,182,183,184,186,187,189,191,192,193,196,199,200,201,202,204,206,208,210,211,212,213,219,220,221,224,227,228,231,232,235,237,239,241,242,244,246,247,248,253,258,260,263,265,267,274,276,282,285,288,292,302,303,304,305,307,311,312,320,322,323,329,331,335,339,341,343,355,371,377,381,393,397],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[165,159,17,163,42,176,174,194,204,175,173,212,219,212,191,181,155,191,185,211,219,155,189,181,213,17,32,24,32,22,31,29,30,44,47,47,51,28,48,40,28,8,48,39,36,37,40,56,25,55,43,58,38,45,29,12,29,55,8,29,50,36,34,37,38,14,114,13,15,13,21,121,15,19,37,9,14,19,19,13,14,21,8,21,21,16,88,28,38,19,22,13,9,13,37,18,13,14,12,46,47,43,39,8,95,15,14,29,13,36,37,22,37,42,37,12,38,8,17,39,17,89,9,29,15,17,39,42,41,9,38,253,18,37,37,43],\"y\":[0.8913043478260869,0.8985507246376812,0.8768115942028986,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.8913043478260869,0.8985507246376812,0.8913043478260869,0.8768115942028986,0.9057971014492754,0.8840579710144928,0.8768115942028986,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8768115942028986,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.8913043478260869,0.9202898550724637,0.8913043478260869,0.9057971014492754,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.8985507246376812,0.927536231884058,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9202898550724637,0.9130434782608695,0.8840579710144928,0.9130434782608695,0.9057971014492754,0.8913043478260869,0.9202898550724637,0.9057971014492754,0.8985507246376812,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9202898550724637,0.9202898550724637,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.8985507246376812,0.9130434782608695,0.9057971014492754,0.9130434782608695,0.927536231884058,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.9130434782608695,0.8840579710144928,0.9057971014492754,0.8985507246376812,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.9202898550724637,0.9057971014492754,0.9202898550724637,0.9057971014492754,0.9057971014492754,0.9130434782608695,0.8913043478260869,0.8985507246376812,0.9057971014492754,0.9057971014492754,0.9202898550724637,0.9130434782608695,0.8985507246376812,0.9057971014492754,0.9130434782608695,0.927536231884058,0.9130434782608695,0.9130434782608695,0.9347826086956522,0.8985507246376812,0.9130434782608695,0.9130434782608695,0.8985507246376812,0.9130434782608695],\"type\":\"scatter\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.082],\"title\":{\"text\":\"bagging_fraction\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.10200000000000001,0.184],\"title\":{\"text\":\"bagging_freq\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.20400000000000001,0.28600000000000003],\"title\":{\"text\":\"feature_fraction\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.306,0.388],\"title\":{\"text\":\"lambda_l1\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.40800000000000003,0.49000000000000005],\"title\":{\"text\":\"lambda_l2\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.51,0.592],\"title\":{\"text\":\"learning_rate\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.6120000000000001,0.6940000000000001],\"title\":{\"text\":\"max_depth\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.7140000000000001,0.796],\"title\":{\"text\":\"min_child_samples\"}},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.8160000000000001,0.898],\"title\":{\"text\":\"n_estimators\"}},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.9179999999999999,0.9999999999999999],\"title\":{\"text\":\"num_leaves\"}},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"Slice Plot\"},\"width\":3000},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6b682b52-b655-4da0-99f6-209bc3bbb5b3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_bagging_freq</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_lambda_l1</th>\n",
       "      <th>params_lambda_l2</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_samples</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>0.957037</td>\n",
       "      <td>2022-04-17 18:03:34.086389</td>\n",
       "      <td>2022-04-17 18:03:34.165389</td>\n",
       "      <td>0 days 00:00:00.079000</td>\n",
       "      <td>0.775455</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465958</td>\n",
       "      <td>3.310190</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.417592</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>129</td>\n",
       "      <td>35</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>0.957037</td>\n",
       "      <td>2022-04-17 18:03:37.069390</td>\n",
       "      <td>2022-04-17 18:03:37.149389</td>\n",
       "      <td>0 days 00:00:00.079999</td>\n",
       "      <td>0.917095</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470508</td>\n",
       "      <td>3.226576</td>\n",
       "      <td>0.411580</td>\n",
       "      <td>0.394874</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>106</td>\n",
       "      <td>31</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>313</td>\n",
       "      <td>0.956931</td>\n",
       "      <td>2022-04-17 18:03:29.113388</td>\n",
       "      <td>2022-04-17 18:03:29.196389</td>\n",
       "      <td>0 days 00:00:00.083001</td>\n",
       "      <td>0.918224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456510</td>\n",
       "      <td>3.736656</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>0.416415</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>114</td>\n",
       "      <td>13</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>0.956931</td>\n",
       "      <td>2022-04-17 18:03:35.456387</td>\n",
       "      <td>2022-04-17 18:03:35.537387</td>\n",
       "      <td>0 days 00:00:00.081000</td>\n",
       "      <td>0.900986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430843</td>\n",
       "      <td>3.216504</td>\n",
       "      <td>0.963260</td>\n",
       "      <td>0.473157</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>149</td>\n",
       "      <td>69</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>0.956931</td>\n",
       "      <td>2022-04-17 18:03:22.641389</td>\n",
       "      <td>2022-04-17 18:03:22.712388</td>\n",
       "      <td>0 days 00:00:00.070999</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472601</td>\n",
       "      <td>2.882538</td>\n",
       "      <td>1.113400</td>\n",
       "      <td>0.446219</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>129</td>\n",
       "      <td>24</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "364     364  0.957037 2022-04-17 18:03:34.086389 2022-04-17 18:03:34.165389   \n",
       "394     394  0.957037 2022-04-17 18:03:37.069390 2022-04-17 18:03:37.149389   \n",
       "313     313  0.956931 2022-04-17 18:03:29.113388 2022-04-17 18:03:29.196389   \n",
       "378     378  0.956931 2022-04-17 18:03:35.456387 2022-04-17 18:03:35.537387   \n",
       "251     251  0.956931 2022-04-17 18:03:22.641389 2022-04-17 18:03:22.712388   \n",
       "\n",
       "                  duration  params_bagging_fraction  params_bagging_freq  \\\n",
       "364 0 days 00:00:00.079000                 0.775455                    0   \n",
       "394 0 days 00:00:00.079999                 0.917095                    0   \n",
       "313 0 days 00:00:00.083001                 0.918224                    0   \n",
       "378 0 days 00:00:00.081000                 0.900986                    0   \n",
       "251 0 days 00:00:00.070999                 0.910783                    0   \n",
       "\n",
       "     params_feature_fraction  params_lambda_l1  params_lambda_l2  \\\n",
       "364                 0.465958          3.310190          0.001821   \n",
       "394                 0.470508          3.226576          0.411580   \n",
       "313                 0.456510          3.736656          0.193365   \n",
       "378                 0.430843          3.216504          0.963260   \n",
       "251                 0.472601          2.882538          1.113400   \n",
       "\n",
       "     params_learning_rate  params_max_depth  params_min_child_samples  \\\n",
       "364              0.417592                10                        45   \n",
       "394              0.394874                10                        37   \n",
       "313              0.416415                10                        39   \n",
       "378              0.473157                10                        57   \n",
       "251              0.446219                10                        52   \n",
       "\n",
       "     params_n_estimators  params_num_leaves   state  \n",
       "364                  129                 35  PRUNED  \n",
       "394                  106                 31  PRUNED  \n",
       "313                  114                 13  PRUNED  \n",
       "378                  149                 69  PRUNED  \n",
       "251                  129                 24  PRUNED  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle \n",
    "\n",
    "class Objective:\n",
    "    \n",
    "  def __init__(self):\n",
    "        self.best_booster = None\n",
    "        self._booster = None\n",
    "        \n",
    "  def __call__(self,trial) :\n",
    "\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 0.95),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 0.95),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"n_estimators\":trial.suggest_int(\"n_estimators\",100,1000, log=True),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\",6,10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01,0.5),     \n",
    "      }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[pruning_callback])\n",
    "    self._booster= gbm \n",
    "    \n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "  def callback(self, study, trial):\n",
    "    if study.best_trial == trial:\n",
    "       self.best_booster = self._booster \n",
    "     \n",
    "objective = Objective()\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=400,callbacks=[objective.callback])\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "best_model_LGBM = objective.best_booster\n",
    "print(best_model_LGBM)\n",
    "pickle.dump(best_model_LGBM, open(\"LGBM Model_Optimized_withOptuna.dat\",\"wb\"))\n",
    " \n",
    "new_preds= best_model_LGBM.predict(valid_x) \n",
    "new_pred_labels_Best_modelLGBM=np.rint(new_preds)\n",
    "\n",
    "print(\"Best score is:\",sklearn.metrics.accuracy_score(valid_y, new_pred_labels_Best_modelLGBM))\n",
    "\n",
    "FIG=optuna.visualization.plot_optimization_history(study)\n",
    "FIG.show()\n",
    "FIG2=optuna.visualization.plot_slice(study)\n",
    "FIG2.show()\n",
    "data_frame=study.trials_dataframe() \n",
    "data_frame.sort_values(by='value',ascending=False, inplace=True)\n",
    "data_frame.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure Feature Importance (MDI) LGBMClassifier Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1368 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "feature_importance =best_model_LGBM.feature_importance()\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(20, 19))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(names)[sorted_idx]) \n",
    "plt.title(\"Feature Importance (MDI) LGBMClassifier Model\")\n",
    "save_fig(\"Feature Importance (MDI) LGBMClassifier Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure ROC Curve LGBMClassifier Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt \n",
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(valid_y, new_pred_labels_Best_modelLGBM)\n",
    "\n",
    "auc_score = metrics.auc(fpr, tpr)\n",
    "\n",
    "# clear current figure\n",
    "plt.clf()\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "# it's helpful to add a diagonal to indicate where chance \n",
    "# scores lie (i.e. just flipping a coin)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "save_fig(\"ROC Curve LGBMClassifier Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
